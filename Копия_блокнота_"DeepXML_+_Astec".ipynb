{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arina080803/DeepXML-ASTEC/blob/Colab-Models/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22DeepXML_%2B_Astec%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0I7i-PJjNXs"
      },
      "outputs": [],
      "source": [
        "! mkdir work_directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImytyNrXj7Iv",
        "outputId": "b81bb2c8-f2bf-4055-b6b5-711baebae393"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/work_directory\n"
          ]
        }
      ],
      "source": [
        "%cd work_directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fIREFm-kSLQ"
      },
      "outputs": [],
      "source": [
        "! mkdir programs data models results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEsVyzcFk7IF",
        "outputId": "dc83e161-4e15-4328-a034-22da92c84f17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/work_directory/programs\n"
          ]
        }
      ],
      "source": [
        "%cd programs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKk1t-OPlAwG",
        "outputId": "d170f24a-9448-49f5-afc7-46743fd2f893"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deepxml'...\n",
            "remote: Enumerating objects: 1692, done.\u001b[K\n",
            "remote: Counting objects: 100% (250/250), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 1692 (delta 232), reused 228 (delta 228), pack-reused 1442\u001b[K\n",
            "Receiving objects: 100% (1692/1692), 327.67 KiB | 1.33 MiB/s, done.\n",
            "Resolving deltas: 100% (1260/1260), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/Extreme-classification/deepxml.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHDToLcelhtc",
        "outputId": "b8e25666-eeca-40ef-b7f6-94786e43b046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pyxclib'...\n",
            "remote: Enumerating objects: 1273, done.\u001b[K\n",
            "remote: Counting objects: 100% (364/364), done.\u001b[K\n",
            "remote: Compressing objects: 100% (135/135), done.\u001b[K\n",
            "remote: Total 1273 (delta 252), reused 312 (delta 229), pack-reused 909\u001b[K\n",
            "Receiving objects: 100% (1273/1273), 7.63 MiB | 12.17 MiB/s, done.\n",
            "Resolving deltas: 100% (743/743), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/kunaldahiya/pyxclib.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DF9IHT2plm_g",
        "outputId": "29a1d17e-a472-4487-ea9b-0cd6db36bc9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/work_directory/programs/pyxclib\n"
          ]
        }
      ],
      "source": [
        "%cd pyxclib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "t8OxO5BipEqw",
        "outputId": "88f1b7f4-1f73-4b28-d3bd-83c453520581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libeigen3-dev pybind11-dev python3-numpy\n",
            "Suggested packages:\n",
            "  libeigen3-doc libmpfrc++-dev pybind11-doc python-numpy-doc python3-pytest\n",
            "The following NEW packages will be installed:\n",
            "  libeigen3-dev pybind11-dev python3-numpy python3-pybind11\n",
            "0 upgraded, 4 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 4,826 kB of archives.\n",
            "After this operation, 29.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 pybind11-dev all 2.9.1-2 [146 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-numpy amd64 1:1.21.5-1ubuntu22.04.1 [3,467 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-pybind11 all 2.9.1-2 [156 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libeigen3-dev all 3.4.0-2ubuntu2 [1,056 kB]\n",
            "Fetched 4,826 kB in 2s (2,649 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package pybind11-dev.\n",
            "(Reading database ... 121913 files and directories currently installed.)\n",
            "Preparing to unpack .../pybind11-dev_2.9.1-2_all.deb ...\n",
            "Unpacking pybind11-dev (2.9.1-2) ...\n",
            "Selecting previously unselected package python3-numpy.\n",
            "Preparing to unpack .../python3-numpy_1%3a1.21.5-1ubuntu22.04.1_amd64.deb ...\n",
            "Unpacking python3-numpy (1:1.21.5-1ubuntu22.04.1) ...\n",
            "Selecting previously unselected package python3-pybind11.\n",
            "Preparing to unpack .../python3-pybind11_2.9.1-2_all.deb ...\n",
            "Unpacking python3-pybind11 (2.9.1-2) ...\n",
            "Selecting previously unselected package libeigen3-dev.\n",
            "Preparing to unpack .../libeigen3-dev_3.4.0-2ubuntu2_all.deb ...\n",
            "Unpacking libeigen3-dev (3.4.0-2ubuntu2) ...\n",
            "Setting up pybind11-dev (2.9.1-2) ...\n",
            "Setting up libeigen3-dev (3.4.0-2ubuntu2) ...\n",
            "Setting up python3-numpy (1:1.21.5-1ubuntu22.04.1) ...\n",
            "Setting up python3-pybind11 (2.9.1-2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "! sudo apt -y install python3-pybind11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "blV3x2uNnCDe",
        "outputId": "77c83fd0-6bcd-4739-f1ec-d3421c51954e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nmslib\n",
            "  Downloading nmslib-2.1.1.tar.gz (188 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/188.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m184.3/188.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11<2.6.2 (from nmslib)\n",
            "  Using cached pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from nmslib) (5.9.5)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from nmslib) (1.25.2)\n",
            "Building wheels for collected packages: nmslib\n",
            "  Building wheel for nmslib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nmslib: filename=nmslib-2.1.1-cp310-cp310-linux_x86_64.whl size=13547941 sha256=702a59f6371dc5faf912e5f2d46cb3059dd964ded2b2737e0bdfe9ad7e1718ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/1a/5d/4cc754a5b1a88405cad184b76f823897a63a8d19afcd4b9314\n",
            "Successfully built nmslib\n",
            "Installing collected packages: pybind11, nmslib\n",
            "  Attempting uninstall: pybind11\n",
            "    Found existing installation: pybind11 2.9.1\n",
            "    Uninstalling pybind11-2.9.1:\n",
            "      Successfully uninstalled pybind11-2.9.1\n",
            "Successfully installed nmslib-2.1.1 pybind11-2.6.1\n",
            "Compiling xclib/utils/_sparse.pyx because it changed.\n",
            "[1/1] Cythonizing xclib/utils/_sparse.pyx\n",
            "running install\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating xclib.egg-info\n",
            "writing xclib.egg-info/PKG-INFO\n",
            "writing dependency_links to xclib.egg-info/dependency_links.txt\n",
            "writing requirements to xclib.egg-info/requires.txt\n",
            "writing top-level names to xclib.egg-info/top_level.txt\n",
            "writing manifest file 'xclib.egg-info/SOURCES.txt'\n",
            "reading manifest file 'xclib.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'xclib.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "creating build/lib.linux-x86_64-cpython-310/xclib\n",
            "copying xclib/__init__.py -> build/lib.linux-x86_64-cpython-310/xclib\n",
            "creating build/lib.linux-x86_64-cpython-310/xclib/classifier\n",
            "copying xclib/classifier/kcentroid.py -> build/lib.linux-x86_64-cpython-310/xclib/classifier\n",
            "copying xclib/classifier/_svm.py -> build/lib.linux-x86_64-cpython-310/xclib/classifier\n",
            "copying xclib/classifier/__init__.py -> build/lib.linux-x86_64-cpython-310/xclib/classifier\n",
            "copying xclib/classifier/base.py -> build/lib.linux-x86_64-cpython-310/xclib/classifier\n",
            "copying xclib/classifier/mips.py -> build/lib.linux-x86_64-cpython-310/xclib/classifier\n",
            "copying xclib/classifier/parameters_base.py -> build/lib.linux-x86_64-cpython-310/xclib/classifier\n",
            "copying xclib/classifier/ova.py -> build/lib.linux-x86_64-cpython-310/xclib/classifier\n",
            "copying xclib/classifier/slice.py -> build/lib.linux-x86_64-cpython-310/xclib/classifier\n",
            "copying xclib/classifier/knn.py -> build/lib.linux-x86_64-cpython-310/xclib/classifier\n",
            "copying xclib/classifier/parameters.py -> build/lib.linux-x86_64-cpython-310/xclib/classifier\n",
            "creating build/lib.linux-x86_64-cpython-310/xclib/utils\n",
            "copying xclib/utils/shortlist.py -> build/lib.linux-x86_64-cpython-310/xclib/utils\n",
            "copying xclib/utils/text.py -> build/lib.linux-x86_64-cpython-310/xclib/utils\n",
            "copying xclib/utils/matrix.py -> build/lib.linux-x86_64-cpython-310/xclib/utils\n",
            "copying xclib/utils/clustering_gpu.py -> build/lib.linux-x86_64-cpython-310/xclib/utils\n",
            "copying xclib/utils/misc.py -> build/lib.linux-x86_64-cpython-310/xclib/utils\n",
            "copying xclib/utils/__init__.py -> build/lib.linux-x86_64-cpython-310/xclib/utils\n",
            "copying xclib/utils/graph.py -> build/lib.linux-x86_64-cpython-310/xclib/utils\n",
            "copying xclib/utils/clustering.py -> build/lib.linux-x86_64-cpython-310/xclib/utils\n",
            "copying xclib/utils/dense.py -> build/lib.linux-x86_64-cpython-310/xclib/utils\n",
            "copying xclib/utils/sparse.py -> build/lib.linux-x86_64-cpython-310/xclib/utils\n",
            "copying xclib/utils/ann.py -> build/lib.linux-x86_64-cpython-310/xclib/utils\n",
            "copying xclib/utils/analysis.py -> build/lib.linux-x86_64-cpython-310/xclib/utils\n",
            "copying xclib/utils/numba_utils.py -> build/lib.linux-x86_64-cpython-310/xclib/utils\n",
            "creating build/lib.linux-x86_64-cpython-310/xclib/evaluation\n",
            "copying xclib/evaluation/xc_metrics.py -> build/lib.linux-x86_64-cpython-310/xclib/evaluation\n",
            "copying xclib/evaluation/__init__.py -> build/lib.linux-x86_64-cpython-310/xclib/evaluation\n",
            "creating build/lib.linux-x86_64-cpython-310/xclib/embeddings\n",
            "copying xclib/embeddings/fasttext_embeddings.py -> build/lib.linux-x86_64-cpython-310/xclib/embeddings\n",
            "copying xclib/embeddings/__init__.py -> build/lib.linux-x86_64-cpython-310/xclib/embeddings\n",
            "creating build/lib.linux-x86_64-cpython-310/xclib/data\n",
            "copying xclib/data/data_loader.py -> build/lib.linux-x86_64-cpython-310/xclib/data\n",
            "copying xclib/data/data_statistics.py -> build/lib.linux-x86_64-cpython-310/xclib/data\n",
            "copying xclib/data/data_utils.py -> build/lib.linux-x86_64-cpython-310/xclib/data\n",
            "copying xclib/data/features.py -> build/lib.linux-x86_64-cpython-310/xclib/data\n",
            "copying xclib/data/__init__.py -> build/lib.linux-x86_64-cpython-310/xclib/data\n",
            "copying xclib/data/labels.py -> build/lib.linux-x86_64-cpython-310/xclib/data\n",
            "copying xclib/utils/_sparse.c -> build/lib.linux-x86_64-cpython-310/xclib/utils\n",
            "running build_ext\n",
            "building 'xclib.utils._sparse' extension\n",
            "creating build/temp.linux-x86_64-cpython-310\n",
            "creating build/temp.linux-x86_64-cpython-310/xclib\n",
            "creating build/temp.linux-x86_64-cpython-310/xclib/utils\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I/usr/include/python3.10 -c xclib/utils/_sparse.c -o build/temp.linux-x86_64-cpython-310/xclib/utils/_sparse.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1929\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/arrayobject.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kxclib/utils/_sparse.c:1277\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wcpp\u0007-Wcpp\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/xclib/utils/_sparse.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-310/xclib/utils/_sparse.cpython-310-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/xclib\n",
            "creating build/bdist.linux-x86_64/egg/xclib/classifier\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/classifier/kcentroid.py -> build/bdist.linux-x86_64/egg/xclib/classifier\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/classifier/_svm.py -> build/bdist.linux-x86_64/egg/xclib/classifier\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/classifier/__init__.py -> build/bdist.linux-x86_64/egg/xclib/classifier\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/classifier/base.py -> build/bdist.linux-x86_64/egg/xclib/classifier\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/classifier/mips.py -> build/bdist.linux-x86_64/egg/xclib/classifier\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/classifier/parameters_base.py -> build/bdist.linux-x86_64/egg/xclib/classifier\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/classifier/ova.py -> build/bdist.linux-x86_64/egg/xclib/classifier\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/classifier/slice.py -> build/bdist.linux-x86_64/egg/xclib/classifier\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/classifier/knn.py -> build/bdist.linux-x86_64/egg/xclib/classifier\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/classifier/parameters.py -> build/bdist.linux-x86_64/egg/xclib/classifier\n",
            "creating build/bdist.linux-x86_64/egg/xclib/utils\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/utils/shortlist.py -> build/bdist.linux-x86_64/egg/xclib/utils\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/utils/text.py -> build/bdist.linux-x86_64/egg/xclib/utils\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/utils/_sparse.c -> build/bdist.linux-x86_64/egg/xclib/utils\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/utils/matrix.py -> build/bdist.linux-x86_64/egg/xclib/utils\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/utils/clustering_gpu.py -> build/bdist.linux-x86_64/egg/xclib/utils\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/utils/misc.py -> build/bdist.linux-x86_64/egg/xclib/utils\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/utils/_sparse.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/xclib/utils\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/utils/__init__.py -> build/bdist.linux-x86_64/egg/xclib/utils\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/utils/graph.py -> build/bdist.linux-x86_64/egg/xclib/utils\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/utils/clustering.py -> build/bdist.linux-x86_64/egg/xclib/utils\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/utils/dense.py -> build/bdist.linux-x86_64/egg/xclib/utils\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/utils/sparse.py -> build/bdist.linux-x86_64/egg/xclib/utils\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/utils/ann.py -> build/bdist.linux-x86_64/egg/xclib/utils\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/utils/analysis.py -> build/bdist.linux-x86_64/egg/xclib/utils\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/utils/numba_utils.py -> build/bdist.linux-x86_64/egg/xclib/utils\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/__init__.py -> build/bdist.linux-x86_64/egg/xclib\n",
            "creating build/bdist.linux-x86_64/egg/xclib/evaluation\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/evaluation/xc_metrics.py -> build/bdist.linux-x86_64/egg/xclib/evaluation\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/evaluation/__init__.py -> build/bdist.linux-x86_64/egg/xclib/evaluation\n",
            "creating build/bdist.linux-x86_64/egg/xclib/embeddings\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/embeddings/fasttext_embeddings.py -> build/bdist.linux-x86_64/egg/xclib/embeddings\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/embeddings/__init__.py -> build/bdist.linux-x86_64/egg/xclib/embeddings\n",
            "creating build/bdist.linux-x86_64/egg/xclib/data\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/data/data_loader.py -> build/bdist.linux-x86_64/egg/xclib/data\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/data/data_statistics.py -> build/bdist.linux-x86_64/egg/xclib/data\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/data/data_utils.py -> build/bdist.linux-x86_64/egg/xclib/data\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/data/features.py -> build/bdist.linux-x86_64/egg/xclib/data\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/data/__init__.py -> build/bdist.linux-x86_64/egg/xclib/data\n",
            "copying build/lib.linux-x86_64-cpython-310/xclib/data/labels.py -> build/bdist.linux-x86_64/egg/xclib/data\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/classifier/kcentroid.py to kcentroid.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/classifier/_svm.py to _svm.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/classifier/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/classifier/base.py to base.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/classifier/mips.py to mips.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/classifier/parameters_base.py to parameters_base.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/classifier/ova.py to ova.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/classifier/slice.py to slice.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/classifier/knn.py to knn.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/classifier/parameters.py to parameters.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/utils/shortlist.py to shortlist.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/utils/text.py to text.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/utils/matrix.py to matrix.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/utils/clustering_gpu.py to clustering_gpu.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/utils/misc.py to misc.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/utils/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/utils/graph.py to graph.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/utils/clustering.py to clustering.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/utils/dense.py to dense.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/utils/sparse.py to sparse.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/utils/ann.py to ann.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/utils/analysis.py to analysis.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/utils/numba_utils.py to numba_utils.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/evaluation/xc_metrics.py to xc_metrics.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/evaluation/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/embeddings/fasttext_embeddings.py to fasttext_embeddings.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/embeddings/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/data/data_loader.py to data_loader.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/data/data_statistics.py to data_statistics.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/data/data_utils.py to data_utils.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/data/features.py to features.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/data/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/data/labels.py to labels.cpython-310.pyc\n",
            "creating stub loader for xclib/utils/_sparse.cpython-310-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/xclib/utils/_sparse.py to _sparse.cpython-310.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying xclib.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying xclib.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying xclib.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying xclib.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying xclib.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "xclib.utils.__pycache__._sparse.cpython-310: module references __file__\n",
            "creating dist\n",
            "creating 'dist/xclib-0.97-py3.10-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing xclib-0.97-py3.10-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.10/dist-packages/xclib-0.97-py3.10-linux-x86_64.egg\n",
            "Extracting xclib-0.97-py3.10-linux-x86_64.egg to /usr/local/lib/python3.10/dist-packages\n",
            "Adding xclib 0.97 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/xclib-0.97-py3.10-linux-x86_64.egg\n",
            "Processing dependencies for xclib==0.97\n",
            "Searching for fasttext\n",
            "Reading https://pypi.org/simple/fasttext/\n",
            "Downloading https://files.pythonhosted.org/packages/9f/3b/9a10b95eaf565358339162848863197c3f0a29b540ca22b2951df2d66a48/fasttext-0.9.3.tar.gz#sha256=eb03f2ef6340c6ac9e4398a30026f05471da99381b307aafe2f56e4cd26baaef\n",
            "Best match: fasttext 0.9.3\n",
            "Processing fasttext-0.9.3.tar.gz\n",
            "Writing /tmp/easy_install-obptld8l/fasttext-0.9.3/setup.cfg\n",
            "Running fasttext-0.9.3/setup.py -q bdist_egg --dist-dir /tmp/easy_install-obptld8l/fasttext-0.9.3/egg-dist-tmp-oki7frps\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/dist.py:755: SetuptoolsDeprecationWarning: Invalid dash-separated options\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Usage of dash-separated 'description-file' will not be supported in future\n",
            "        versions. Please use the underscore name 'description_file' instead.\n",
            "\n",
            "        This deprecation is overdue, please update your project and remove deprecated\n",
            "        calls to avoid build errors in the future.\n",
            "\n",
            "        See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  opt = self.warn_dash_deprecation(opt, section)\n",
            "warning: no files found matching 'PATENTS'\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "\u001b[01m\u001b[Kpython/fasttext_module/fasttext/pybind/fasttext_pybind.cc:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kpython/fasttext_module/fasttext/pybind/fasttext_pybind.cc:347:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint32_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kstd::vector<long int>::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  347 |             for (int32_t i = 0; \u001b[01;35m\u001b[Ki < vocab_freq.size()\u001b[m\u001b[K; i++) {\n",
            "      |                                 \u001b[01;35m\u001b[K~~^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kpython/fasttext_module/fasttext/pybind/fasttext_pybind.cc:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kpython/fasttext_module/fasttext/pybind/fasttext_pybind.cc:361:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint32_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kstd::vector<long int>::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  361 |             for (int32_t i = 0; \u001b[01;35m\u001b[Ki < labels_freq.size()\u001b[m\u001b[K; i++) {\n",
            "      |                                 \u001b[01;35m\u001b[K~~^~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/args.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::Args::parseArgs(const std::vector<std::__cxx11::basic_string<char> >&)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/args.cc:121:23:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ and ‘\u001b[01m\u001b[Kstd::vector<std::__cxx11::basic_string<char> >::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  121 |   for (int ai = 2; \u001b[01;35m\u001b[Kai < args.size()\u001b[m\u001b[K; ai += 2) {\n",
            "      |                    \u001b[01;35m\u001b[K~~~^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/args.cc:222:19:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcatching polymorphic type ‘\u001b[01m\u001b[Kclass std::out_of_range\u001b[m\u001b[K’ by value [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wcatch-value=\u0007-Wcatch-value=\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  222 |     } catch (std::\u001b[01;35m\u001b[Kout_of_range\u001b[m\u001b[K) {\n",
            "      |                   \u001b[01;35m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/densematrix.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::DenseMatrix::uniform(fasttext::real, unsigned int, int32_t)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/densematrix.cc:52:23:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ and ‘\u001b[01m\u001b[Kunsigned int\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   52 |     for (int i = 0; \u001b[01;35m\u001b[Ki < thread\u001b[m\u001b[K; i++) {\n",
            "      |                     \u001b[01;35m\u001b[K~~^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/densematrix.cc:55:27:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint32_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kstd::vector<std::thread>::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   55 |     for (int32_t i = 0; \u001b[01;35m\u001b[Ki < threads.size()\u001b[m\u001b[K; i++) {\n",
            "      |                         \u001b[01;35m\u001b[K~~^~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/dictionary.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::Dictionary::computeSubwords(const string&, std::vector<int>&, std::vector<std::__cxx11::basic_string<char> >*) const\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/dictionary.cc:181:52:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Ksize_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  181 |     for (size_t j = i, n = 1; j < word.size() && \u001b[01;35m\u001b[Kn <= args_->maxn\u001b[m\u001b[K; n++) {\n",
            "      |                                                  \u001b[01;35m\u001b[K~~^~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/dictionary.cc:186:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Ksize_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  186 |       if (\u001b[01;35m\u001b[Kn >= args_->minn\u001b[m\u001b[K && !(n == 1 && (i == 0 || j == word.size()))) {\n",
            "      |           \u001b[01;35m\u001b[K~~^~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/dictionary.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::Dictionary::initNgrams()\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/dictionary.cc:198:24:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Ksize_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kint32_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  198 |   for (size_t i = 0; \u001b[01;35m\u001b[Ki < size_\u001b[m\u001b[K; i++) {\n",
            "      |                      \u001b[01;35m\u001b[K~~^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/dictionary.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::Dictionary::initTableDiscard()\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/dictionary.cc:296:24:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Ksize_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kint32_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  296 |   for (size_t i = 0; \u001b[01;35m\u001b[Ki < size_\u001b[m\u001b[K; i++) {\n",
            "      |                      \u001b[01;35m\u001b[K~~^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/dictionary.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::Dictionary::addWordNgrams(std::vector<int>&, const std::vector<int>&, int32_t) const\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/dictionary.cc:316:25:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint32_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kstd::vector<int>::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  316 |   for (int32_t i = 0; \u001b[01;35m\u001b[Ki < hashes.size()\u001b[m\u001b[K; i++) {\n",
            "      |                       \u001b[01;35m\u001b[K~~^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/dictionary.cc:318:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint32_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kstd::vector<int>::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  318 |     for (int32_t j = i + 1; \u001b[01;35m\u001b[Kj < hashes.size()\u001b[m\u001b[K && j < i + n; j++) {\n",
            "      |                             \u001b[01;35m\u001b[K~~^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/dictionary.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::Dictionary::prune(std::vector<int>&)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/dictionary.cc:565:25:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint32_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kstd::vector<fasttext::entry>::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  565 |   for (int32_t i = 0; \u001b[01;35m\u001b[Ki < words_.size()\u001b[m\u001b[K; i++) {\n",
            "      |                       \u001b[01;35m\u001b[K~~^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/dictionary.cc:567:12:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint32_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kstd::vector<int>::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  567 |         (\u001b[01;35m\u001b[Kj < words.size()\u001b[m\u001b[K && words[j] == i)) {\n",
            "      |          \u001b[01;35m\u001b[K~~^~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::FastText::getWordVector(fasttext::Vector&, const string&) const\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:114:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ and ‘\u001b[01m\u001b[Kstd::vector<int>::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  114 |   for (int i = 0; \u001b[01;35m\u001b[Ki < ngrams.size()\u001b[m\u001b[K; i++) {\n",
            "      |                   \u001b[01;35m\u001b[K~~^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:314:12:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Ksize_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kconst int\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  314 |     if (\u001b[01;35m\u001b[Ki1 == eosid\u001b[m\u001b[K && i2 == eosid) { // satisfy strict weak ordering\n",
            "      |         \u001b[01;35m\u001b[K~~~^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:314:27:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Ksize_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kconst int\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  314 |     if (i1 == eosid && \u001b[01;35m\u001b[Ki2 == eosid\u001b[m\u001b[K) { // satisfy strict weak ordering\n",
            "      |                        \u001b[01;35m\u001b[K~~~^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:317:18:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kconst int\u001b[m\u001b[K’ and ‘\u001b[01m\u001b[Ksize_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  317 |     return \u001b[01;35m\u001b[Keosid == i1\u001b[m\u001b[K || (eosid != i2 && norms[i1] > norms[i2]);\n",
            "      |            \u001b[01;35m\u001b[K~~~~~~^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:317:34:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kconst int\u001b[m\u001b[K’ and ‘\u001b[01m\u001b[Ksize_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  317 |     return eosid == i1 || (\u001b[01;35m\u001b[Keosid != i2\u001b[m\u001b[K && norms[i1] > norms[i2]);\n",
            "      |                            \u001b[01;35m\u001b[K~~~~~~^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::FastText::quantize(const fasttext::Args&, const TrainCallback&)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:337:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kconst size_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kconst long unsigned int\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kint64_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  337 |   if (qargs.cutoff > 0 && \u001b[01;35m\u001b[Kqargs.cutoff < input->size(0)\u001b[m\u001b[K) {\n",
            "      |                           \u001b[01;35m\u001b[K~~~~~~~~~~~~~^~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:342:24:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ and ‘\u001b[01m\u001b[Kstd::vector<int>::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  342 |     for (auto i = 0; \u001b[01;35m\u001b[Ki < idx.size()\u001b[m\u001b[K; i++) {\n",
            "      |                      \u001b[01;35m\u001b[K~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::FastText::cbow(fasttext::Model::State&, fasttext::real, const std::vector<int>&)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:393:25:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint32_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kstd::vector<int>::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  393 |   for (int32_t w = 0; \u001b[01;35m\u001b[Kw < line.size()\u001b[m\u001b[K; w++) {\n",
            "      |                       \u001b[01;35m\u001b[K~~^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:397:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint32_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kstd::vector<int>::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  397 |       if (c != 0 && w + c >= 0 && \u001b[01;35m\u001b[Kw + c < line.size()\u001b[m\u001b[K) {\n",
            "      |                                   \u001b[01;35m\u001b[K~~~~~~^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::FastText::skipgram(fasttext::Model::State&, fasttext::real, const std::vector<int>&)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:411:25:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint32_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kstd::vector<int>::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  411 |   for (int32_t w = 0; \u001b[01;35m\u001b[Kw < line.size()\u001b[m\u001b[K; w++) {\n",
            "      |                       \u001b[01;35m\u001b[K~~^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:415:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint32_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kstd::vector<int>::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  415 |       if (c != 0 && w + c >= 0 && \u001b[01;35m\u001b[Kw + c < line.size()\u001b[m\u001b[K) {\n",
            "      |                                   \u001b[01;35m\u001b[K~~~~~~^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::FastText::getSentenceVector(std::istream&, fasttext::Vector&)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:495:27:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint32_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kstd::vector<int>::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  495 |     for (int32_t i = 0; \u001b[01;35m\u001b[Ki < line.size()\u001b[m\u001b[K; i++) {\n",
            "      |                         \u001b[01;35m\u001b[K~~^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kstd::vector<std::pair<std::__cxx11::basic_string<char>, fasttext::Vector> > fasttext::FastText::getNgramVectors(const string&) const\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:530:25:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint32_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kstd::vector<int>::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  530 |   for (int32_t i = 0; \u001b[01;35m\u001b[Ki < ngrams.size()\u001b[m\u001b[K; i++) {\n",
            "      |                       \u001b[01;35m\u001b[K~~^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kstd::vector<std::pair<float, std::__cxx11::basic_string<char> > > fasttext::FastText::getNN(const fasttext::DenseMatrix&, const fasttext::Vector&, int32_t, const std::set<std::__cxx11::basic_string<char> >&)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:591:23:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kstd::vector<std::pair<float, std::__cxx11::basic_string<char> > >::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kint32_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  591 |       if (\u001b[01;35m\u001b[Kheap.size() == k\u001b[m\u001b[K && similarity < heap.front().first) {\n",
            "      |           \u001b[01;35m\u001b[K~~~~~~~~~~~~^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:596:23:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kstd::vector<std::pair<float, std::__cxx11::basic_string<char> > >::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kint32_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  596 |       if (\u001b[01;35m\u001b[Kheap.size() > k\u001b[m\u001b[K) {\n",
            "      |           \u001b[01;35m\u001b[K~~~~~~~~~~~~^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kstd::shared_ptr<fasttext::Matrix> fasttext::FastText::getInputMatrixFromFile(const string&) const\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:696:24:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Ksize_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kint64_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  696 |   for (size_t i = 0; \u001b[01;35m\u001b[Ki < n\u001b[m\u001b[K; i++) {\n",
            "      |                      \u001b[01;35m\u001b[K~~^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:701:26:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Ksize_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kint64_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  701 |     for (size_t j = 0; \u001b[01;35m\u001b[Kj < dim\u001b[m\u001b[K; j++) {\n",
            "      |                        \u001b[01;35m\u001b[K~~^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:713:24:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Ksize_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kint64_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  713 |   for (size_t i = 0; \u001b[01;35m\u001b[Ki < n\u001b[m\u001b[K; i++) {\n",
            "      |                      \u001b[01;35m\u001b[K~~^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:718:26:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Ksize_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kint64_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  718 |     for (size_t j = 0; \u001b[01;35m\u001b[Kj < dim\u001b[m\u001b[K; j++) {\n",
            "      |                        \u001b[01;35m\u001b[K~~^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::FastText::startThreads(const TrainCallback&)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:803:25:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint32_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kstd::vector<std::thread>::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  803 |   for (int32_t i = 0; \u001b[01;35m\u001b[Ki < threads.size()\u001b[m\u001b[K; i++) {\n",
            "      |                       \u001b[01;35m\u001b[K~~^~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/loss.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::Loss::findKBest(int32_t, fasttext::real, fasttext::Predictions&, const fasttext::Vector&) const\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/loss.cc:83:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kstd::vector<std::pair<float, int> >::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kint32_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   83 |     if (\u001b[01;35m\u001b[Kheap.size() == k\u001b[m\u001b[K && std_log(output[i]) < heap.front().first) {\n",
            "      |         \u001b[01;35m\u001b[K~~~~~~~~~~~~^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/loss.cc:88:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kstd::vector<std::pair<float, int> >::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kint32_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   88 |     if (\u001b[01;35m\u001b[Kheap.size() > k\u001b[m\u001b[K) {\n",
            "      |         \u001b[01;35m\u001b[K~~~~~~~~~~~~^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/loss.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvirtual fasttext::real fasttext::HierarchicalSoftmaxLoss::forward(const std::vector<int>&, int32_t, fasttext::Model::State&, fasttext::real, bool)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/loss.cc:257:25:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint32_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kstd::vector<int>::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  257 |   for (int32_t i = 0; \u001b[01;35m\u001b[Ki < pathToRoot.size()\u001b[m\u001b[K; i++) {\n",
            "      |                       \u001b[01;35m\u001b[K~~^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/loss.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::HierarchicalSoftmaxLoss::dfs(int32_t, fasttext::real, int32_t, fasttext::real, fasttext::Predictions&, const fasttext::Vector&) const\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/loss.cc:282:19:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kstd::vector<std::pair<float, int> >::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kint32_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  282 |   if (\u001b[01;35m\u001b[Kheap.size() == k\u001b[m\u001b[K && score < heap.front().first) {\n",
            "      |       \u001b[01;35m\u001b[K~~~~~~~~~~~~^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/loss.cc:289:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kstd::vector<std::pair<float, int> >::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kint32_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  289 |     if (\u001b[01;35m\u001b[Kheap.size() > k\u001b[m\u001b[K) {\n",
            "      |         \u001b[01;35m\u001b[K~~~~~~~~~~~~^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/productquantizer.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::ProductQuantizer::load(std::istream&)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/productquantizer.cc:246:22:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ and ‘\u001b[01m\u001b[Kstd::vector<float>::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  246 |   for (auto i = 0; \u001b[01;35m\u001b[Ki < centroids_.size()\u001b[m\u001b[K; i++) {\n",
            "      |                    \u001b[01;35m\u001b[K~~^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "Adding fasttext 0.9.3 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/fasttext-0.9.3-py3.10-linux-x86_64.egg\n",
            "Searching for numba==0.58.1\n",
            "Best match: numba 0.58.1\n",
            "Adding numba 0.58.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for scikit-learn==1.2.2\n",
            "Best match: scikit-learn 1.2.2\n",
            "Adding scikit-learn 1.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for nmslib==2.1.1\n",
            "Best match: nmslib 2.1.1\n",
            "Adding nmslib 2.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for numpy==1.25.2\n",
            "Best match: numpy 1.25.2\n",
            "Adding numpy 1.25.2 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.10 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for setuptools==67.7.2\n",
            "Best match: setuptools 67.7.2\n",
            "Adding setuptools 67.7.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for pybind11==2.6.1\n",
            "Best match: pybind11 2.6.1\n",
            "Adding pybind11 2.6.1 to easy-install.pth file\n",
            "Installing pybind11-config script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for llvmlite==0.41.1\n",
            "Best match: llvmlite 0.41.1\n",
            "Adding llvmlite 0.41.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for threadpoolctl==3.5.0\n",
            "Best match: threadpoolctl 3.5.0\n",
            "Adding threadpoolctl 3.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for joblib==1.4.2\n",
            "Best match: joblib 1.4.2\n",
            "Adding joblib 1.4.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for scipy==1.11.4\n",
            "Best match: scipy 1.11.4\n",
            "Adding scipy 1.11.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for psutil==5.9.5\n",
            "Best match: psutil 5.9.5\n",
            "Adding psutil 5.9.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Finished processing dependencies for xclib==0.97\n"
          ]
        }
      ],
      "source": [
        "! pip install nmslib\n",
        "! python setup.py install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGfq15-1pTY7",
        "outputId": "61f5d120-5686-4c1c-9909-173004339fee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/work_directory/data\n"
          ]
        }
      ],
      "source": [
        "%cd /content/work_directory/data\n",
        "#%cd ./data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9URx-LJs26kj"
      },
      "outputs": [],
      "source": [
        "#!unzip /content/work_directory/data/LF-AmazonTitles-131K-20240508T105620Z-001.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vOA5_rjphyz",
        "outputId": "57783e17-1d41-4d80-edc2-0ec4fc80bf76",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1VlfcdJKJA99223fLEawRmrXhXpwjwJKn\n",
            "From (redirected): https://drive.google.com/uc?id=1VlfcdJKJA99223fLEawRmrXhXpwjwJKn&confirm=t&uuid=9df5c4bc-d7d6-4958-b701-5c89d680e17b\n",
            "To: /content/work_directory/data/LF-AmazonTitles-131K.bow.zip\n",
            "100% 72.8M/72.8M [00:00<00:00, 81.1MB/s]\n",
            "Archive:  LF-AmazonTitles-131K.bow.zip\n",
            "   creating: LF-AmazonTitles-131K/\n",
            "  inflating: LF-AmazonTitles-131K/filter_labels_test.txt  \n",
            "  inflating: LF-AmazonTitles-131K/train.txt  \n",
            "  inflating: LF-AmazonTitles-131K/Xf.txt  \n",
            "  inflating: LF-AmazonTitles-131K/fasttextB_embeddings_300d.npy  \n",
            "  inflating: LF-AmazonTitles-131K/Yf.txt  \n",
            "  inflating: LF-AmazonTitles-131K/label_raw_ids.txt  \n",
            "  inflating: LF-AmazonTitles-131K/test_raw_ids.txt  \n",
            "  inflating: LF-AmazonTitles-131K/filter_labels_train.txt  \n",
            "  inflating: LF-AmazonTitles-131K/test.txt  \n",
            "  inflating: LF-AmazonTitles-131K/train_raw_ids.txt  \n"
          ]
        }
      ],
      "source": [
        "! gdown 1VlfcdJKJA99223fLEawRmrXhXpwjwJKn\n",
        "# /content/work_directory/data/LF-AmazonTitles-131K.bow.zip\n",
        "! unzip *.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAbcFXKVrvZw",
        "outputId": "85d65392-ee16-4d92-88fb-66c6e8d1798f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/work_directory/programs/deepxml/deepxml/tools\n"
          ]
        }
      ],
      "source": [
        "#%cd .\n",
        "#%cd work_directory\n",
        "%cd /content/work_directory/programs/deepxml/deepxml/tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OH9TRnQyquR1"
      },
      "outputs": [],
      "source": [
        "! perl convert_format.pl /content/work_directory/programs/deepxml/deepxml/tools/LF-AmazonTitles-131K/train.txt /content/work_directory/programs/deepxml/deepxml/tools/LF-AmazonTitles-131K/trn_X_Xf.txt /content/work_directory/programs/deepxml/deepxml/tools/LF-AmazonTitles-131K/trn_X_Y.txt\n",
        "! perl convert_format.pl /content/work_directory/programs/deepxml/deepxml/tools/LF-AmazonTitles-131K/test.txt /content/work_directory/programs/deepxml/deepxml/tools/LF-AmazonTitles-131K/tst_X_Xf.txt /content/work_directory/programs/deepxml/deepxml/tools/LF-AmazonTitles-131K/tst_X_Y.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2D7t9c9ZscaW",
        "outputId": "99992d08-1910-446c-a4d8-e626f95cf1c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/work_directory/programs/deepxml/deepxml\n",
            "/content/work_directory/programs/deepxml/deepxml/run_scripts\n"
          ]
        }
      ],
      "source": [
        "%cd ..\n",
        "%cd /content/work_directory/programs/deepxml/deepxml/run_scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfHyitzps3I7",
        "outputId": "ce240dce-ca3a-4f8d-b522-f9f220b316e3",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hnswlib\n",
            "  Downloading hnswlib-0.8.0.tar.gz (36 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hnswlib) (1.25.2)\n",
            "Building wheels for collected packages: hnswlib\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.8.0-cp310-cp310-linux_x86_64.whl size=2323492 sha256=d6e3f9b302b2e1fe4082d862ff6e186cd8dd28c9fa422404188e1122d5ff71a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/a9/3e/3e5d59ee41664eb31a4e6de67d1846f86d16d93c45f277c4e7\n",
            "Successfully built hnswlib\n",
            "Installing collected packages: hnswlib\n",
            "Successfully installed hnswlib-0.8.0\n"
          ]
        }
      ],
      "source": [
        "! pip install hnswlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IJLSNwNumxdB",
        "outputId": "c48a124c-ebc8-479b-a506-13c2ba4fdc84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.19.5\n",
            "  Downloading numpy-1.19.5.zip (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: numpy\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for numpy \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for numpy (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for numpy\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build numpy\n",
            "\u001b[31mERROR: Could not build wheels for numpy, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install numpy==1.19.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2NKU7RkjpoEA",
        "outputId": "625260da-4354-4689-ffdc-e1658c5fcfd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.25.2\n",
            "Uninstalling numpy-1.25.2:\n",
            "  Would remove:\n",
            "    /usr/local/bin/f2py\n",
            "    /usr/local/bin/f2py3\n",
            "    /usr/local/bin/f2py3.10\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy-1.25.2.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy.libs/libgfortran-040039e1.so.5.0.0\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy.libs/libopenblas64_p-r0-5007b62f.3.23.dev.so\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy.libs/libquadmath-96973f99.so.0.0.0\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled numpy-1.25.2\n",
            "Collecting numpy==1.23.1\n",
            "  Downloading numpy-1.23.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.1 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.23.1 which is incompatible.\n",
            "tensorflow 2.15.0 requires numpy<2.0.0,>=1.23.5, but you have numpy 1.23.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.1\n"
          ]
        }
      ],
      "source": [
        "! python -m pip uninstall numpy\n",
        "! python -m pip install numpy==1.23.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8ym7Ay-ui5w",
        "outputId": "86dc54db-84fe-4993-9ed3-b30747704e01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using existing data for surrogate task!\n",
            "\n",
            "Setting the seed value: 108\n",
            "Initialized token embeddings!\n",
            "Model parameters:  Namespace(dataset='EURLex-4K', data_dir='/content/work_directory/data', model_dir='/content/work_directory/models/DeepXML/Astec/EURLex-4K/v_0_108/surrogate', result_dir='/content/work_directory/results/DeepXML/Astec/EURLex-4K/v_0_108/surrogate', model_fname='model', pred_fname='predictions', trn_feat_fname='trn_X_Xf.txt', val_feat_fname='tst_X_Xf.txt', tst_feat_fname='tst_X_Xf.txt', trn_label_fname='trn_X_Y.txt', val_label_fname='tst_X_Y.txt', feature_type='sparse', tst_label_fname='tst_X_Y.txt', arch='/content/work_directory/programs/deepxml/deepxml/run_scripts/Astec.json', learning_rate=0.01, surrogate_mapping='/content/work_directory/data/EURLex-4K/deepxml.Astec/1024.108/surrogate_mapping.txt', dlr_step=14, last_epoch=0, shortlist_method='static', model_method='full', ns_method='kcentroid', ann_method='hnsw', seed=108, top_k=100, num_workers=6, ann_threads=12, num_clf_partitions=1, label_indices=None, feature_indices=None, efC=300, num_nbrs=300, efS=300, M=100, retrain_hnsw_after=1, num_labels=1024, vocabulary_dims=40000, padding_idx=0, out_fname='out', dlr_factor=0.5, momentum=0.9, weight_decay=0.0, dropout=0.5, optim='Adam', embedding_dims=300, embeddings='fasttextB_embeddings_300d.npy', validate_after=5, num_epochs=20, batch_size=255, num_centroids=1, beta=0.3, res_init='eye', label_padding_index=None, mode='train', init='token_embeddings', keep_invalid=False, freeze_intermediate=False, use_shortlist=False, save_intermediate=True, use_pretrained_shortlist=False, validate=True, bias=True, shuffle=True, devices=['cuda:0'], normalize=True, nbn_rel=False, update_shortlist=False, huge_dataset=False, use_intermediate_for_shorty=False, get_only=['knn', 'clf', 'combined'], A=0.55, B=1.5, use_reranker=True, surrogate_threshold=1024, surrogate_method=1, save_predictions=True)\n",
            "\n",
            "Model configuration:  Transform(\n",
            "  (transform): Astec(\n",
            "    (embeddings): Embedding(40001, 300, cuda:0, reduction=sum, padding_idx=0, sparse=True)\n",
            "    (relu): ReLU()\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            ")\n",
            "(Transform fine): Transform(\n",
            "  (transform): Residual(\n",
            "    (hidden_layer): Sequential(\n",
            "      (0): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "(Classifier): Linear(300, 1024, cuda:0, bias=True)\n",
            "\n",
            "Loading training data.\n",
            "/usr/local/lib/python3.10/dist-packages/xclib-0.97-py3.10-linux-x86_64.egg/xclib/data/data_utils.py:263: UserWarning: Header mis-match from inferred shape!\n",
            "  warnings.warn(\"Header mis-match from inferred shape!\")\n",
            "/usr/local/lib/python3.10/dist-packages/xclib-0.97-py3.10-linux-x86_64.egg/xclib/utils/sparse.py:160: UserWarning: Header mis-match from inferred shape!\n",
            "  warnings.warn(\"Header mis-match from inferred shape!\")\n",
            "Surrogate mapping is not None, mapping labels\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Loading validation data.\n",
            "Surrogate mapping is not None, mapping labels\n",
            "loss: 0.03313: 100% 32/32 [00:05<00:00,  5.43it/s]\n",
            "Epoch: 0, loss: 0.082169, time: 5.90 sec\n",
            "100% 15/15 [00:01<00:00, 10.50it/s]\n",
            "Model saved after epoch: 0\n",
            "P@1: 3.89, loss: 0.032921, time: 1.43 sec\n",
            "  0% 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss: 0.03144: 100% 32/32 [00:02<00:00, 12.73it/s]\n",
            "Epoch: 1, loss: 0.032651, time: 2.51 sec\n",
            "loss: 0.02912: 100% 32/32 [00:02<00:00, 12.53it/s]\n",
            "Epoch: 2, loss: 0.029727, time: 2.56 sec\n",
            "loss: 0.02598: 100% 32/32 [00:04<00:00,  7.80it/s]\n",
            "Epoch: 3, loss: 0.026942, time: 4.10 sec\n",
            "loss: 0.02351: 100% 32/32 [00:04<00:00,  7.60it/s]\n",
            "Epoch: 4, loss: 0.024697, time: 4.21 sec\n",
            "loss: 0.02158: 100% 32/32 [00:02<00:00, 12.41it/s]\n",
            "Epoch: 5, loss: 0.023028, time: 2.58 sec\n",
            "100% 15/15 [00:01<00:00, 11.89it/s]\n",
            "Model saved after epoch: 5\n",
            "P@1: 56.24, loss: 0.021450, time: 1.26 sec\n",
            "loss: 0.02279: 100% 32/32 [00:02<00:00, 12.47it/s]\n",
            "Epoch: 6, loss: 0.021605, time: 2.57 sec\n",
            "loss: 0.02074: 100% 32/32 [00:02<00:00, 12.95it/s]\n",
            "Epoch: 7, loss: 0.020338, time: 2.47 sec\n",
            "loss: 0.01902: 100% 32/32 [00:03<00:00,  9.99it/s]\n",
            "Epoch: 8, loss: 0.019218, time: 3.20 sec\n",
            "loss: 0.01731: 100% 32/32 [00:04<00:00,  7.82it/s]\n",
            "Epoch: 9, loss: 0.018133, time: 4.09 sec\n",
            "loss: 0.01669: 100% 32/32 [00:02<00:00, 11.92it/s]\n",
            "Epoch: 10, loss: 0.017189, time: 2.69 sec\n",
            "100% 15/15 [00:01<00:00, 12.02it/s]\n",
            "Model saved after epoch: 10\n",
            "P@1: 69.68, loss: 0.017886, time: 1.25 sec\n",
            "loss: 0.01729: 100% 32/32 [00:02<00:00, 12.62it/s]\n",
            "Epoch: 11, loss: 0.016295, time: 2.54 sec\n",
            "loss: 0.01657: 100% 32/32 [00:02<00:00, 12.01it/s]\n",
            "Epoch: 12, loss: 0.015443, time: 2.67 sec\n",
            "loss: 0.01397: 100% 32/32 [00:03<00:00,  9.47it/s]\n",
            "Epoch: 13, loss: 0.014713, time: 3.38 sec\n",
            "Adjusted learning rate to: 0.005\n",
            "loss: 0.01320: 100% 32/32 [00:04<00:00,  7.78it/s]\n",
            "Epoch: 14, loss: 0.013898, time: 4.12 sec\n",
            "loss: 0.01349: 100% 32/32 [00:02<00:00, 12.04it/s]\n",
            "Epoch: 15, loss: 0.013457, time: 2.66 sec\n",
            "100% 15/15 [00:01<00:00, 12.10it/s]\n",
            "Model saved after epoch: 15\n",
            "Purging network checkpoint: checkpoint_net_1.pkl\n",
            "P@1: 74.19, loss: 0.016797, time: 1.24 sec\n",
            "loss: 0.01269: 100% 32/32 [00:02<00:00, 12.12it/s]\n",
            "Epoch: 16, loss: 0.013072, time: 2.64 sec\n",
            "loss: 0.01310: 100% 32/32 [00:02<00:00, 12.98it/s]\n",
            "Epoch: 17, loss: 0.012713, time: 2.47 sec\n",
            "loss: 0.01265: 100% 32/32 [00:03<00:00,  9.77it/s]\n",
            "Epoch: 18, loss: 0.012401, time: 3.28 sec\n",
            "loss: 0.01277: 100% 32/32 [00:04<00:00,  7.46it/s]\n",
            "Epoch: 19, loss: 0.012078, time: 4.29 sec\n",
            "Purging network checkpoint: checkpoint_net_6.pkl\n",
            "Training time: 64.94 sec, Validation time: 5.19 sec, Shortlist time: 0.00 sec, Model size: 47.30 MB\n",
            "Saving model at: /content/work_directory/models/DeepXML/Astec/EURLex-4K/v_0_108/surrogate/model_network.pkl\n",
            "\n",
            "Setting the seed value: 108\n",
            "Model parameters:  Namespace(dataset='EURLex-4K', data_dir='/content/work_directory/data', model_dir='/content/work_directory/models/DeepXML/Astec/EURLex-4K/v_0_108/surrogate', result_dir='/content/work_directory/results/DeepXML/Astec/EURLex-4K/v_0_108/surrogate', model_fname='model', pred_fname='predictions', trn_feat_fname='trn_X_Xf.txt', val_feat_fname='tst_X_Xf.txt', tst_feat_fname='tst_X_Xf.txt', trn_label_fname='trn_X_Y.txt', val_label_fname='tst_X_Y.txt', feature_type='sparse', tst_label_fname='tst_X_Y.txt', arch='/content/work_directory/programs/deepxml/deepxml/run_scripts/Astec.json', learning_rate=0.01, surrogate_mapping='/content/work_directory/data/EURLex-4K/deepxml.Astec/1024.108/surrogate_mapping.txt', dlr_step=14, last_epoch=0, shortlist_method='static', model_method='full', ns_method='kcentroid', ann_method='hnsw', seed=108, top_k=100, num_workers=6, ann_threads=12, num_clf_partitions=1, label_indices=None, feature_indices=None, efC=300, num_nbrs=300, efS=300, M=100, retrain_hnsw_after=1, num_labels=1024, vocabulary_dims=40000, padding_idx=0, out_fname='out', dlr_factor=0.5, momentum=0.9, weight_decay=0.0, dropout=0.5, optim='Adam', embedding_dims=300, embeddings='fasttextB_embeddings_300d.npy', validate_after=5, num_epochs=20, batch_size=255, num_centroids=1, beta=0.3, res_init='eye', label_padding_index=None, mode='predict', init='token_embeddings', keep_invalid=False, freeze_intermediate=False, use_shortlist=False, save_intermediate=True, use_pretrained_shortlist=False, validate=True, bias=True, shuffle=True, devices=['cuda:0'], normalize=True, nbn_rel=False, update_shortlist=False, huge_dataset=False, use_intermediate_for_shorty=False, get_only=['knn', 'clf', 'combined'], A=0.55, B=1.5, use_reranker=True, surrogate_threshold=1024, surrogate_method=1, save_predictions=True)\n",
            "\n",
            "Model configuration:  Transform(\n",
            "  (transform): Astec(\n",
            "    (embeddings): Embedding(40001, 300, cuda:0, reduction=sum, padding_idx=0, sparse=True)\n",
            "    (relu): ReLU()\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            ")\n",
            "(Transform fine): Transform(\n",
            "  (transform): Residual(\n",
            "    (hidden_layer): Sequential(\n",
            "      (0): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "(Classifier): Linear(300, 1024, cuda:0, bias=True)\n",
            "\n",
            "Shapes are fine, Not padding again.\n",
            "/usr/local/lib/python3.10/dist-packages/xclib-0.97-py3.10-linux-x86_64.egg/xclib/data/data_utils.py:263: UserWarning: Header mis-match from inferred shape!\n",
            "  warnings.warn(\"Header mis-match from inferred shape!\")\n",
            "Surrogate mapping is not None, mapping labels\n",
            "100% 15/15 [00:01<00:00, 11.71it/s]\n",
            "Prediction time (total): 1.29 sec.,Prediction time (per sample): 0.34 msec., P@k(%): (clf): 74.90,66.82,59.82,53.91,48.65\n",
            "\n",
            "Setting the seed value: 108\n",
            "Freezing intermediate model parameters!\n",
            "Loading the intermediate representation.\n",
            "Model parameters:  Namespace(dataset='EURLex-4K', data_dir='/content/work_directory/data', model_dir='/content/work_directory/models/DeepXML/Astec/EURLex-4K/v_0_108/extreme', result_dir='/content/work_directory/results/DeepXML/Astec/EURLex-4K/v_0_108/extreme', model_fname='model', pred_fname='predictions', trn_feat_fname='trn_X_Xf.txt', val_feat_fname='tst_X_Xf.txt', tst_feat_fname='tst_X_Xf.txt', trn_label_fname='trn_X_Y.txt', val_label_fname='tst_X_Y.txt', feature_type='sparse', tst_label_fname='tst_X_Y.txt', arch='/content/work_directory/programs/deepxml/deepxml/run_scripts/Astec.json', learning_rate=0.007, surrogate_mapping=None, dlr_step=14, last_epoch=0, shortlist_method='hybrid', model_method='shortlist', ns_method='ensemble', ann_method='hnsw', seed=108, top_k=100, num_workers=6, ann_threads=18, num_clf_partitions=1, label_indices=None, feature_indices=None, efC=300, num_nbrs=500, efS=400, M=100, retrain_hnsw_after=1, num_labels=3786, vocabulary_dims=40000, padding_idx=0, out_fname='out', dlr_factor=0.5, momentum=0.9, weight_decay=0.0, dropout=0.5, optim='Adam', embedding_dims=300, embeddings='fasttextB_embeddings_300d.npy', validate_after=5, num_epochs=20, batch_size=255, num_centroids=1, beta=0.5, res_init='eye', label_padding_index=3786, mode='train', init='intermediate', keep_invalid=False, freeze_intermediate=True, use_shortlist=True, save_intermediate=True, use_pretrained_shortlist=False, validate=True, bias=True, shuffle=True, devices=['cuda:0'], normalize=True, nbn_rel=False, update_shortlist=False, huge_dataset=False, use_intermediate_for_shorty=True, get_only=['knn', 'clf', 'combined'], A=0.55, B=1.5, use_reranker=True, surrogate_threshold=1024, surrogate_method=1, save_predictions=True)\n",
            "\n",
            "Model configuration:  Transform(\n",
            "  (transform): Astec(\n",
            "    (embeddings): Embedding(40001, 300, cuda:0, reduction=sum, padding_idx=0, sparse=True)\n",
            "    (relu): ReLU()\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            ")\n",
            "(Transform fine): Transform(\n",
            "  (transform): Residual(\n",
            "    (hidden_layer): Sequential(\n",
            "      (0): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "(Classifier): SparseLinear(300, 3787, cuda:0, bias=True, padding_idx=3786, sparse=True)\n",
            "\n",
            "Loading training data.\n",
            "/usr/local/lib/python3.10/dist-packages/xclib-0.97-py3.10-linux-x86_64.egg/xclib/utils/sparse.py:160: UserWarning: Header mis-match from inferred shape!\n",
            "  warnings.warn(\"Header mis-match from inferred shape!\")\n",
            "Computing and reusing intermediate document embeddings to save computations.\n",
            "Using the default encoder.\n",
            "100% 13/13 [00:02<00:00,  4.73it/s]\n",
            "Loading validation data.\n",
            "Updating shortlist at epoch: 0\n",
            "Using pre-trained embeddings for shortlist.\n",
            "\n",
            "0%   10   20   30   40   50   60   70   80   90   100%\n",
            "|----|----|----|----|----|----|----|----|----|----|\n",
            "***************************************************\n",
            "\n",
            "0%   10   20   30   40   50   60   70   80   90   100%\n",
            "|----|----|----|----|----|----|----|----|----|----|\n",
            "***************************************************\n",
            "Using the default encoder.\n",
            "100% 4/4 [00:01<00:00,  3.53it/s]\n",
            "ANN train time: 11.45 sec\n",
            "loss: 24.78381: 100% 50/50 [00:04<00:00, 12.18it/s]\n",
            "Epoch: 0, loss: 44.786852, time: 4.11 sec\n",
            "100% 15/15 [00:01<00:00,  8.81it/s]\n",
            "Model saved after epoch: 0\n",
            "P@k (knn): 70.65,61.12,52.93,46.87,41.95 (clf): 50.91,41.86,36.22,32.11,28.99 (ens): 57.84,48.78,43.49,39.43,36.22, loss: 22.971401, time: 1.80 sec\n",
            "loss: 21.06733: 100% 50/50 [00:06<00:00,  7.46it/s]\n",
            "Epoch: 1, loss: 22.367789, time: 6.70 sec\n",
            "loss: 17.95767: 100% 50/50 [00:04<00:00, 11.37it/s]\n",
            "Epoch: 2, loss: 19.416388, time: 4.40 sec\n",
            "loss: 16.89653: 100% 50/50 [00:04<00:00, 12.40it/s]\n",
            "Epoch: 3, loss: 17.411815, time: 4.03 sec\n",
            "loss: 15.33449: 100% 50/50 [00:05<00:00,  9.56it/s]\n",
            "Epoch: 4, loss: 15.920184, time: 5.23 sec\n",
            "loss: 13.75354: 100% 50/50 [00:06<00:00,  8.05it/s]\n",
            "Epoch: 5, loss: 14.722343, time: 6.21 sec\n",
            "100% 15/15 [00:01<00:00,  8.54it/s]\n",
            "Model saved after epoch: 5\n",
            "P@k (knn): 70.65,61.12,52.93,46.87,41.95 (clf): 75.79,66.91,59.51,53.53,48.34 (ens): 76.21,66.97,59.95,53.71,48.65, loss: 15.799095, time: 1.86 sec\n",
            "loss: 13.03974: 100% 50/50 [00:04<00:00, 12.10it/s]\n",
            "Epoch: 6, loss: 13.740719, time: 4.13 sec\n",
            "loss: 13.58053: 100% 50/50 [00:05<00:00,  9.90it/s]\n",
            "Epoch: 7, loss: 12.872022, time: 5.05 sec\n",
            "loss: 12.09757: 100% 50/50 [00:06<00:00,  7.63it/s]\n",
            "Epoch: 8, loss: 12.032403, time: 6.56 sec\n",
            "loss: 11.19012: 100% 50/50 [00:04<00:00, 12.27it/s]\n",
            "Epoch: 9, loss: 11.112490, time: 4.08 sec\n",
            "loss: 10.43849: 100% 50/50 [00:04<00:00, 12.40it/s]\n",
            "Epoch: 10, loss: 10.345407, time: 4.03 sec\n",
            "100% 15/15 [00:02<00:00,  7.42it/s]\n",
            "Model saved after epoch: 10\n",
            "P@k (knn): 70.65,61.12,52.93,46.87,41.95 (clf): 77.79,70.23,63.32,56.96,51.61 (ens): 77.92,70.53,63.57,57.14,51.67, loss: 14.460275, time: 2.16 sec\n",
            "loss: 9.19313: 100% 50/50 [00:06<00:00,  7.27it/s]\n",
            "Epoch: 11, loss: 9.764021, time: 6.88 sec\n",
            "loss: 9.61429: 100% 50/50 [00:04<00:00, 12.39it/s]\n",
            "Epoch: 12, loss: 9.243252, time: 4.04 sec\n",
            "loss: 9.06256: 100% 50/50 [00:04<00:00, 11.87it/s]\n",
            "Epoch: 13, loss: 8.892016, time: 4.21 sec\n",
            "Adjusted learning rate to: 0.0035\n",
            "loss: 8.42820: 100% 50/50 [00:05<00:00,  8.88it/s]\n",
            "Epoch: 14, loss: 8.294682, time: 5.63 sec\n",
            "loss: 8.17211: 100% 50/50 [00:04<00:00, 11.94it/s]\n",
            "Epoch: 15, loss: 8.041060, time: 4.19 sec\n",
            "100% 15/15 [00:01<00:00,  8.72it/s]\n",
            "Model saved after epoch: 15\n",
            "Purging network checkpoint: checkpoint_net_1.pkl\n",
            "P@k (knn): 70.65,61.12,52.93,46.87,41.95 (clf): 79.23,71.06,64.31,58.14,53.01 (ens): 79.52,71.12,64.51,58.23,52.96, loss: 14.006931, time: 1.82 sec\n",
            "loss: 7.54655: 100% 50/50 [00:04<00:00, 12.06it/s]\n",
            "Epoch: 16, loss: 7.856837, time: 4.15 sec\n",
            "loss: 7.84562: 100% 50/50 [00:06<00:00,  7.20it/s]\n",
            "Epoch: 17, loss: 7.716269, time: 6.94 sec\n",
            "loss: 7.92358: 100% 50/50 [00:04<00:00, 12.03it/s]\n",
            "Epoch: 18, loss: 7.569510, time: 4.16 sec\n",
            "loss: 7.40516: 100% 50/50 [00:04<00:00, 11.79it/s]\n",
            "Epoch: 19, loss: 7.437501, time: 4.24 sec\n",
            "Purging network checkpoint: checkpoint_net_6.pkl\n",
            "Training time: 98.98 sec, Validation time: 7.63 sec, Shortlist time: 11.45 sec, Model size: 77.28 MB\n",
            "Saving model at: /content/work_directory/models/DeepXML/Astec/EURLex-4K/v_0_108/extreme/model_network.pkl\n",
            "\n",
            "Setting the seed value: 108\n",
            "Freezing intermediate model parameters!\n",
            "Model parameters:  Namespace(dataset='EURLex-4K', data_dir='/content/work_directory/data', model_dir='/content/work_directory/models/DeepXML/Astec/EURLex-4K/v_0_108/extreme', result_dir='/content/work_directory/results/DeepXML/Astec/EURLex-4K/v_0_108/extreme', model_fname='model', pred_fname='tst_predictions', trn_feat_fname='trn_X_Xf.txt', val_feat_fname='tst_X_Xf.txt', tst_feat_fname='tst_X_Xf.txt', trn_label_fname='trn_X_Y.txt', val_label_fname='tst_X_Y.txt', feature_type='sparse', tst_label_fname='tst_X_Y.txt', arch='/content/work_directory/programs/deepxml/deepxml/run_scripts/Astec.json', learning_rate=0.007, surrogate_mapping=None, dlr_step=14, last_epoch=0, shortlist_method='hybrid', model_method='shortlist', ns_method='ensemble', ann_method='hnsw', seed=108, top_k=100, num_workers=6, ann_threads=18, num_clf_partitions=1, label_indices=None, feature_indices=None, efC=300, num_nbrs=500, efS=400, M=100, retrain_hnsw_after=1, num_labels=3786, vocabulary_dims=40000, padding_idx=0, out_fname='out', dlr_factor=0.5, momentum=0.9, weight_decay=0.0, dropout=0.5, optim='Adam', embedding_dims=300, embeddings='fasttextB_embeddings_300d.npy', validate_after=5, num_epochs=20, batch_size=255, num_centroids=1, beta=0.5, res_init='eye', label_padding_index=3786, mode='predict', init='intermediate', keep_invalid=False, freeze_intermediate=True, use_shortlist=True, save_intermediate=True, use_pretrained_shortlist=False, validate=True, bias=True, shuffle=True, devices=['cuda:0'], normalize=True, nbn_rel=False, update_shortlist=False, huge_dataset=False, use_intermediate_for_shorty=True, get_only=['knn', 'clf', 'combined'], A=0.55, B=1.5, use_reranker=True, surrogate_threshold=1024, surrogate_method=1, save_predictions=True)\n",
            "\n",
            "Model configuration:  Transform(\n",
            "  (transform): Astec(\n",
            "    (embeddings): Embedding(40001, 300, cuda:0, reduction=sum, padding_idx=0, sparse=True)\n",
            "    (relu): ReLU()\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            ")\n",
            "(Transform fine): Transform(\n",
            "  (transform): Residual(\n",
            "    (hidden_layer): Sequential(\n",
            "      (0): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "(Classifier): SparseLinear(300, 3787, cuda:0, bias=True, padding_idx=3786, sparse=True)\n",
            "\n",
            "Shapes are fine, Not padding again.\n",
            "Loading test data.\n",
            "Fetching shortlist.\n",
            "Using the default encoder.\n",
            "100% 4/4 [00:01<00:00,  3.09it/s]\n",
            "100% 15/15 [00:02<00:00,  6.87it/s]\n",
            "Prediction time (total): 5.99 sec., Prediction time (per sample): 1.57 msec., P@k(%): (knn): 70.65,61.11,52.93,46.87,41.95 (clf): 79.21,71.21,64.37,58.15,52.39 (ens): 79.39,71.27,64.45,58.31,52.71\n",
            "\n",
            "------------------------------\n",
            "classifier\n",
            "79.21,71.21,64.37,58.15,52.39\n",
            "79.21,73.04,68.10,64.18,61.61\n",
            "35.58,39.07,41.42,42.72,43.71\n",
            "35.58,38.17,39.86,40.84,41.60\n",
            "shortlist\n",
            "70.65,61.11,52.93,46.87,41.95\n",
            "70.65,63.29,57.28,53.20,50.79\n",
            "36.12,38.29,38.32,38.51,38.72\n",
            "36.12,37.73,37.85,38.05,38.24\n",
            "beta: 0.10\n",
            "78.97,70.85,63.86,57.48,51.72\n",
            "78.97,72.70,67.66,63.60,60.97\n",
            "37.17,40.38,42.43,43.51,44.53\n",
            "37.17,39.55,41.04,41.87,42.60\n",
            "beta: 0.20\n",
            "79.05,71.19,64.21,58.05,52.31\n",
            "79.05,72.99,67.96,64.07,61.50\n",
            "36.57,39.92,42.04,43.36,44.39\n",
            "36.57,39.06,40.59,41.58,42.33\n",
            "beta: 0.30\n",
            "79.18,71.30,64.29,58.20,52.52\n",
            "79.18,73.11,68.05,64.21,61.69\n",
            "36.30,39.75,41.87,43.20,44.27\n",
            "36.30,38.85,40.40,41.39,42.18\n",
            "beta: 0.40\n",
            "79.21,71.24,64.38,58.25,52.65\n",
            "79.21,73.06,68.12,64.25,61.79\n",
            "36.17,39.56,41.75,43.11,44.27\n",
            "36.17,38.68,40.27,41.28,42.12\n",
            "beta: 0.50\n",
            "79.26,71.25,64.39,58.20,52.60\n",
            "79.26,73.08,68.14,64.24,61.77\n",
            "36.04,39.45,41.64,42.94,44.15\n",
            "36.04,38.56,40.15,41.14,42.00\n",
            "beta: 0.60\n",
            "79.34,71.21,64.37,58.25,52.65\n",
            "79.34,73.07,68.13,64.27,61.81\n",
            "35.96,39.36,41.58,42.91,44.15\n",
            "35.96,38.48,40.08,41.09,41.97\n",
            "beta: 0.75\n",
            "79.29,71.20,64.38,58.32,52.64\n",
            "79.29,73.05,68.13,64.31,61.80\n",
            "35.82,39.23,41.53,42.93,44.05\n",
            "35.82,38.35,40.00,41.05,41.86\n",
            "beta: 0.90\n",
            "79.26,71.24,64.39,58.37,52.72\n",
            "79.26,73.07,68.13,64.34,61.86\n",
            "35.74,39.16,41.45,42.91,44.04\n",
            "35.74,38.28,39.93,41.01,41.84\n",
            "------------------------------\n",
            "\n",
            "Setting the seed value: 108\n",
            "Freezing intermediate model parameters!\n",
            "Model parameters:  Namespace(dataset='EURLex-4K', data_dir='/content/work_directory/data', model_dir='/content/work_directory/models/DeepXML/Astec/EURLex-4K/v_0_108/extreme', result_dir='/content/work_directory/results/DeepXML/Astec/EURLex-4K/v_0_108/extreme', model_fname='model', pred_fname='trn_predictions', trn_feat_fname='trn_X_Xf.txt', val_feat_fname='tst_X_Xf.txt', tst_feat_fname='trn_X_Xf.txt', trn_label_fname='trn_X_Y.txt', val_label_fname='tst_X_Y.txt', feature_type='sparse', tst_label_fname='trn_X_Y.txt', arch='/content/work_directory/programs/deepxml/deepxml/run_scripts/Astec.json', learning_rate=0.007, surrogate_mapping=None, dlr_step=14, last_epoch=0, shortlist_method='hybrid', model_method='shortlist', ns_method='ensemble', ann_method='hnsw', seed=108, top_k=100, num_workers=6, ann_threads=18, num_clf_partitions=1, label_indices=None, feature_indices=None, efC=300, num_nbrs=500, efS=400, M=100, retrain_hnsw_after=1, num_labels=3786, vocabulary_dims=40000, padding_idx=0, out_fname='out', dlr_factor=0.5, momentum=0.9, weight_decay=0.0, dropout=0.5, optim='Adam', embedding_dims=300, embeddings='fasttextB_embeddings_300d.npy', validate_after=5, num_epochs=20, batch_size=255, num_centroids=1, beta=0.5, res_init='eye', label_padding_index=3786, mode='predict', init='intermediate', keep_invalid=False, freeze_intermediate=True, use_shortlist=True, save_intermediate=True, use_pretrained_shortlist=False, validate=True, bias=True, shuffle=True, devices=['cuda:0'], normalize=True, nbn_rel=False, update_shortlist=False, huge_dataset=False, use_intermediate_for_shorty=True, get_only='clf', A=0.55, B=1.5, use_reranker=True, surrogate_threshold=1024, surrogate_method=1, save_predictions=True)\n",
            "\n",
            "Model configuration:  Transform(\n",
            "  (transform): Astec(\n",
            "    (embeddings): Embedding(40001, 300, cuda:0, reduction=sum, padding_idx=0, sparse=True)\n",
            "    (relu): ReLU()\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            ")\n",
            "(Transform fine): Transform(\n",
            "  (transform): Residual(\n",
            "    (hidden_layer): Sequential(\n",
            "      (0): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "(Classifier): SparseLinear(300, 3787, cuda:0, bias=True, padding_idx=3786, sparse=True)\n",
            "\n",
            "Shapes are fine, Not padding again.\n",
            "Loading test data.\n",
            "Fetching shortlist.\n",
            "Using the default encoder.\n",
            "100% 16/16 [00:03<00:00,  5.03it/s]\n",
            "100% 61/61 [00:06<00:00,  9.90it/s]\n",
            "Prediction time (total): 17.12 sec., Prediction time (per sample): 1.10 msec., P@k(%): (knn): 75.78,66.94,59.58,53.20,47.83 (clf): 86.23,83.34,79.66,75.02,69.39 (ens): 86.22,83.16,79.34,74.53,68.80\n",
            "\n",
            "Setting the seed value: 108\n",
            "Initialized token embeddings!\n",
            "Model parameters:  Namespace(dataset='EURLex-4K', data_dir='/content/work_directory/data', model_dir='/content/work_directory/models/DeepXML/Astec/EURLex-4K/v_0_108/reranker', result_dir='/content/work_directory/results/DeepXML/Astec/EURLex-4K/v_0_108/reranker', model_fname='model', pred_fname='trn_predictions', trn_feat_fname='trn_X_Xf.txt', val_feat_fname='tst_X_Xf.txt', tst_feat_fname='tst_X_Xf.txt', trn_label_fname='trn_X_Y.txt', val_label_fname='tst_X_Y.txt', feature_type='sparse', tst_label_fname='tst_X_Y.txt', arch='/content/work_directory/programs/deepxml/deepxml/run_scripts/Astec.json', learning_rate=0.005, surrogate_mapping=None, dlr_step=10, last_epoch=0, shortlist_method='static', model_method='reranker', ns_method='ensemble', ann_method='hnsw', seed=108, top_k=100, num_workers=6, ann_threads=18, num_clf_partitions=1, label_indices=None, feature_indices=None, efC=300, num_nbrs=100, efS=400, M=100, retrain_hnsw_after=1, num_labels=3993, vocabulary_dims=40000, padding_idx=0, out_fname='out', dlr_factor=0.5, momentum=0.9, weight_decay=0.0, dropout=0.5, optim='Adam', embedding_dims=300, embeddings='fasttextB_embeddings_300d.npy', validate_after=5, num_epochs=15, batch_size=255, num_centroids=1, beta=0.6, res_init='eye', label_padding_index=3993, mode='train', init='token_embeddings', keep_invalid=True, freeze_intermediate=False, use_shortlist=True, save_intermediate=False, use_pretrained_shortlist=True, validate=True, bias=True, shuffle=True, devices=['cuda:0'], normalize=True, nbn_rel=False, update_shortlist=False, huge_dataset=False, use_intermediate_for_shorty=True, get_only='clf', A=0.55, B=1.5, use_reranker=True, surrogate_threshold=1024, surrogate_method=1, save_predictions=True)\n",
            "\n",
            "Model configuration:  Transform(\n",
            "  (transform): Astec(\n",
            "    (embeddings): Embedding(40001, 300, cuda:0, reduction=sum, padding_idx=0, sparse=True)\n",
            "    (relu): ReLU()\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            ")\n",
            "(Transform fine): Transform(\n",
            "  (transform): Residual(\n",
            "    (hidden_layer): Sequential(\n",
            "      (0): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "(Classifier): SparseLinear(300, 3994, cuda:0, bias=True, padding_idx=3993, sparse=True)\n",
            "\n",
            "Loading training data.\n",
            "Loading validation data.\n",
            "Updating shortlist at epoch: 0\n",
            "ANN train time: 0.00 sec\n",
            "loss: 12.55568: 100% 61/61 [00:09<00:00,  6.16it/s]\n",
            "Epoch: 0, loss: 13.149019, time: 9.91 sec\n",
            "100% 15/15 [00:01<00:00,  9.10it/s]\n",
            "Model saved after epoch: 0\n",
            "P@k (knn): 79.21,71.21,64.37,58.15,52.39 (clf): 54.21,47.91,43.64,39.93,36.93 (ens): 79.29,70.79,63.43,57.36,51.79, loss: 10.437371, time: 1.67 sec\n",
            "loss: 10.09240: 100% 61/61 [00:06<00:00,  9.57it/s]\n",
            "Epoch: 1, loss: 11.074296, time: 6.37 sec\n",
            "loss: 9.61673: 100% 61/61 [00:09<00:00,  6.25it/s]\n",
            "Epoch: 2, loss: 10.034138, time: 9.77 sec\n",
            "loss: 9.08804: 100% 61/61 [00:06<00:00,  9.76it/s]\n",
            "Epoch: 3, loss: 9.175064, time: 6.25 sec\n",
            "loss: 8.56507: 100% 61/61 [00:07<00:00,  7.79it/s]\n",
            "Epoch: 4, loss: 8.394936, time: 7.83 sec\n",
            "loss: 7.99426: 100% 61/61 [00:06<00:00,  9.56it/s]\n",
            "Epoch: 5, loss: 7.716591, time: 6.38 sec\n",
            "100% 15/15 [00:01<00:00,  9.07it/s]\n",
            "Model saved after epoch: 5\n",
            "P@k (knn): 79.21,71.21,64.37,58.15,52.39 (clf): 78.29,69.56,62.87,56.86,51.30 (ens): 81.36,73.38,66.79,60.38,54.71, loss: 8.138775, time: 1.67 sec\n",
            "loss: 7.29789: 100% 61/61 [00:09<00:00,  6.52it/s]\n",
            "Epoch: 6, loss: 7.093534, time: 9.36 sec\n",
            "loss: 6.47302: 100% 61/61 [00:06<00:00,  9.44it/s]\n",
            "Epoch: 7, loss: 6.557950, time: 6.47 sec\n",
            "loss: 5.82110: 100% 61/61 [00:07<00:00,  7.78it/s]\n",
            "Epoch: 8, loss: 6.089936, time: 7.84 sec\n",
            "loss: 5.70990: 100% 61/61 [00:06<00:00,  9.30it/s]\n",
            "Epoch: 9, loss: 5.709156, time: 6.56 sec\n",
            "Adjusted learning rate to: 0.0025\n",
            "loss: 4.99156: 100% 61/61 [00:07<00:00,  7.78it/s]\n",
            "Epoch: 10, loss: 5.211413, time: 7.85 sec\n",
            "100% 15/15 [00:02<00:00,  7.40it/s]\n",
            "Model saved after epoch: 10\n",
            "P@k (knn): 79.21,71.21,64.37,58.15,52.39 (clf): 79.76,72.26,65.56,59.29,53.37 (ens): 82.28,74.15,67.62,61.43,55.68, loss: 7.472946, time: 2.04 sec\n",
            "loss: 4.96728: 100% 61/61 [00:06<00:00,  9.49it/s]\n",
            "Epoch: 11, loss: 5.017867, time: 6.43 sec\n",
            "loss: 4.70458: 100% 61/61 [00:09<00:00,  6.54it/s]\n",
            "Epoch: 12, loss: 4.779298, time: 9.33 sec\n",
            "loss: 4.64489: 100% 61/61 [00:06<00:00,  9.50it/s]\n",
            "Epoch: 13, loss: 4.656349, time: 6.42 sec\n",
            "loss: 4.73464: 100% 61/61 [00:07<00:00,  7.90it/s]\n",
            "Epoch: 14, loss: 4.500708, time: 7.72 sec\n",
            "Purging network checkpoint: checkpoint_net_1.pkl\n",
            "Training time: 114.49 sec, Validation time: 5.38 sec, Shortlist time: 0.00 sec, Model size: 50.71 MB\n",
            "Saving model at: /content/work_directory/models/DeepXML/Astec/EURLex-4K/v_0_108/reranker/model_network.pkl\n",
            "\n",
            "Setting the seed value: 108\n",
            "Model parameters:  Namespace(dataset='EURLex-4K', data_dir='/content/work_directory/data', model_dir='/content/work_directory/models/DeepXML/Astec/EURLex-4K/v_0_108/reranker', result_dir='/content/work_directory/results/DeepXML/Astec/EURLex-4K/v_0_108/reranker', model_fname='model', pred_fname='tst_predictions_reranker', trn_feat_fname='trn_X_Xf.txt', val_feat_fname='tst_X_Xf.txt', tst_feat_fname='tst_X_Xf.txt', trn_label_fname='trn_X_Y.txt', val_label_fname='tst_X_Y.txt', feature_type='sparse', tst_label_fname='tst_X_Y.txt', arch='/content/work_directory/programs/deepxml/deepxml/run_scripts/Astec.json', learning_rate=0.005, surrogate_mapping=None, dlr_step=10, last_epoch=0, shortlist_method='static', model_method='reranker', ns_method='ensemble', ann_method='hnsw', seed=108, top_k=100, num_workers=6, ann_threads=18, num_clf_partitions=1, label_indices=None, feature_indices=None, efC=300, num_nbrs=100, efS=400, M=100, retrain_hnsw_after=1, num_labels=3993, vocabulary_dims=40000, padding_idx=0, out_fname='out', dlr_factor=0.5, momentum=0.9, weight_decay=0.0, dropout=0.5, optim='Adam', embedding_dims=300, embeddings='fasttextB_embeddings_300d.npy', validate_after=5, num_epochs=15, batch_size=255, num_centroids=1, beta=0.6, res_init='eye', label_padding_index=3993, mode='predict', init='token_embeddings', keep_invalid=True, freeze_intermediate=False, use_shortlist=True, save_intermediate=False, use_pretrained_shortlist=True, validate=True, bias=True, shuffle=True, devices=['cuda:0'], normalize=True, nbn_rel=False, update_shortlist=False, huge_dataset=False, use_intermediate_for_shorty=True, get_only='ens', A=0.55, B=1.5, use_reranker=True, surrogate_threshold=1024, surrogate_method=1, save_predictions=True)\n",
            "\n",
            "Model configuration:  Transform(\n",
            "  (transform): Astec(\n",
            "    (embeddings): Embedding(40001, 300, cuda:0, reduction=sum, padding_idx=0, sparse=True)\n",
            "    (relu): ReLU()\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            ")\n",
            "(Transform fine): Transform(\n",
            "  (transform): Residual(\n",
            "    (hidden_layer): Sequential(\n",
            "      (0): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "(Classifier): SparseLinear(300, 3994, cuda:0, bias=True, padding_idx=3993, sparse=True)\n",
            "\n",
            "Shapes are fine, Not padding again.\n",
            "Loading test data.\n",
            "Fetching shortlist.\n",
            "100% 15/15 [00:01<00:00,  8.93it/s]\n",
            "Prediction time (total): 1.69 sec., Prediction time (per sample): 0.44 msec., P@k(%): (knn): 79.21,71.21,64.37,58.15,52.39 (clf): 79.89,72.32,65.71,59.54,53.75 (ens): 82.31,74.36,67.95,61.69,55.76\n",
            "\n",
            "------------------------------\n",
            "classifier\n",
            "82.31,74.36,67.95,61.69,55.76\n",
            "82.31,76.18,71.58,67.70,65.14\n",
            "38.45,42.17,44.94,46.44,47.74\n",
            "38.45,41.20,43.18,44.32,45.28\n",
            "shortlist\n",
            "70.65,61.11,52.93,46.87,41.95\n",
            "70.65,63.29,57.28,53.20,50.79\n",
            "36.12,38.29,38.32,38.51,38.72\n",
            "36.12,37.73,37.85,38.05,38.24\n",
            "beta: 0.10\n",
            "81.57,73.65,66.04,59.69,53.88\n",
            "81.57,75.47,70.00,65.99,63.39\n",
            "39.57,43.29,44.93,46.03,47.03\n",
            "39.57,42.33,43.57,44.42,45.15\n",
            "beta: 0.20\n",
            "81.91,74.22,67.10,60.88,55.21\n",
            "81.91,75.98,70.88,66.99,64.57\n",
            "39.08,43.04,45.08,46.48,47.80\n",
            "39.08,42.01,43.52,44.57,45.52\n",
            "beta: 0.30\n",
            "82.12,74.42,67.50,61.29,55.52\n",
            "82.12,76.18,71.23,67.36,64.88\n",
            "38.93,42.88,45.10,46.56,47.85\n",
            "38.93,41.86,43.48,44.57,45.51\n",
            "beta: 0.40\n",
            "82.23,74.48,67.59,61.53,55.65\n",
            "82.23,76.25,71.31,67.55,65.02\n",
            "38.89,42.70,45.01,46.64,47.84\n",
            "38.89,41.71,43.39,44.58,45.48\n",
            "beta: 0.50\n",
            "82.31,74.49,67.74,61.63,55.74\n",
            "82.31,76.28,71.44,67.65,65.12\n",
            "38.81,42.57,45.01,46.64,47.86\n",
            "38.81,41.59,43.36,44.56,45.46\n",
            "beta: 0.60\n",
            "82.38,74.49,67.80,61.76,55.83\n",
            "82.38,76.30,71.50,67.76,65.21\n",
            "38.77,42.49,45.00,46.68,47.95\n",
            "38.77,41.52,43.33,44.57,45.51\n",
            "beta: 0.75\n",
            "82.33,74.48,67.90,61.86,56.00\n",
            "82.33,76.28,71.56,67.83,65.32\n",
            "38.59,42.34,45.00,46.69,48.06\n",
            "38.59,41.37,43.28,44.52,45.52\n",
            "beta: 0.90\n",
            "82.28,74.46,67.98,61.99,56.09\n",
            "82.28,76.25,71.60,67.91,65.39\n",
            "38.53,42.26,44.98,46.71,48.09\n",
            "38.53,41.30,43.24,44.51,45.51\n",
            "------------------------------\n",
            "\n",
            "\n",
            "------------------------------\n",
            "Training time (sec): 306.98\n",
            "Model size (MB): 127.99\n",
            "Avg. Prediction time (msec): 2.02\n",
            "------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! ./run_main.sh 0 DeepXML EURLex-4K 0 108"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KBTWWiOw_xA9",
        "outputId": "9c4899b6-0f2e-4f27-ea9b-ff3fea4cbe84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting opacus\n",
            "  Downloading opacus-1.4.1-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.25.2)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.10/dist-packages (from opacus) (2.2.1+cu121)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.11.4)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from opacus) (3.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->opacus) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->opacus) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->opacus) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->opacus) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->opacus) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->opacus) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.0->opacus)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.0->opacus)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.0->opacus)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.0->opacus)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.0->opacus)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.0->opacus)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.0->opacus)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.0->opacus)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.0->opacus)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=2.0->opacus)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.0->opacus)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->opacus) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0->opacus)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0->opacus) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0->opacus) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, opacus\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 opacus-1.4.1\n"
          ]
        }
      ],
      "source": [
        "! pip install opacus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwgBdZOecl4N",
        "outputId": "3a4092ef-f012-4164-a6f2-44090a485f11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n",
            "Mon May 27 16:56:22 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8               9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Проверка доступности GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, using CPU\")\n",
        "\n",
        "# Проверка доступных устройств\n",
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X64DC3VdY5Af",
        "outputId": "a7f28cd5-63b3-4ad8-c365-7248dbc2eb07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Replaced np.bool with np.bool_ in all project files.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/work_directory/programs/deepxml/deepxml/runner.py\", line 413, in <module>\n",
            "    model_type = sys.argv[1]\n",
            "IndexError: list index out of range\n"
          ]
        }
      ],
      "source": [
        "!python fix_numpy_bool.py\n",
        "\n",
        "# Now run your main script\n",
        "!python /content/work_directory/programs/deepxml/deepxml/runner.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neueei8_sUA6",
        "outputId": "4a784db5-2180-4241-c7df-bf1d5d7c10b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/work_directory/../runner.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "! /content/work_directory/programs/deepxml/deepxml/run_scripts/run_main.sh 0 DeepXML EURLex-4K 0 108"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkmfQKI99OUo"
      },
      "source": [
        "Загрузка результатов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Xd5SfGNm9Qy9",
        "outputId": "eb45cece-53d0-484b-d8b7-64750c8c935b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/work_directory/work_directory.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "#%cd .\n",
        "#%cd work_directory\n",
        "\n",
        "import shutil\n",
        "shutil.make_archive('work_directory', 'zip', 'work_directory')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33Af05N_j4AP",
        "outputId": "25198481-e1d0-40c0-ba3f-7bdad6564e38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/work_directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlufbvquwbVu",
        "outputId": "03574d8e-fc6a-4b42-f104-90df389f0bee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/work_directory/programs/deepxml/deepxml/run_scripts\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F3aBHNTuIah"
      },
      "source": [
        "# Одиночные предсказания"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4r0prj3tl6f",
        "outputId": "ca6f7c5e-3150-425e-aac4-0d3e4313cc01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.return_types.topk(\n",
            "values=tensor([[0.3825, 0.3778, 0.3701, 0.3651, 0.3553]], device='cuda:0'),\n",
            "indices=tensor([[2491, 2470, 3384, 1425,  893]], device='cuda:0'))\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "class CorrectAstecModel(nn.Module):\n",
        "    def __init__(self, embedding_matrix, num_labels):\n",
        "        super(CorrectAstecModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag.from_pretrained(embedding_matrix, padding_idx=0, sparse=True)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.transform = nn.Sequential(\n",
        "            nn.Linear(embedding_matrix.shape[1], embedding_matrix.shape[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5)\n",
        "        )\n",
        "        self.classifier = nn.Linear(embedding_matrix.shape[1], num_labels + 1)  # Учитываем padding_idx = 3993\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.transform(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Загрузка эмбеддингов\n",
        "embeddings_path = '/content/work_directory/data/EURLex-4K/fasttextB_embeddings_300d.npy'\n",
        "embeddings = np.load(embeddings_path, allow_pickle=True)\n",
        "\n",
        "# Исправление размера эмбеддингов, если необходимо\n",
        "if embeddings.shape[0] == 40000:\n",
        "    embeddings = np.vstack((embeddings, np.zeros((1, embeddings.shape[1]))))  # Добавляем фиктивную запись\n",
        "\n",
        "embedding_matrix = torch.tensor(embeddings, dtype=torch.float)\n",
        "\n",
        "# Параметры модели\n",
        "num_labels = 3993  # Количество меток\n",
        "\n",
        "# Создание экземпляра модели\n",
        "model = CorrectAstecModel(embedding_matrix, num_labels)\n",
        "\n",
        "# Загрузка параметров модели из state_dict\n",
        "model_path = '/content/work_directory/models/DeepXML/Astec/EURLex-4K/v_0_108/reranker/model_network.pkl'\n",
        "state_dict = torch.load(model_path, map_location='cuda:0')\n",
        "\n",
        "# Корректировка ключей в state_dict\n",
        "new_state_dict = {}\n",
        "for key in state_dict.keys():\n",
        "    if key == 'transform.transform.embeddings.weight':\n",
        "        new_key = 'embedding.weight'\n",
        "    elif key.startswith('transform_fine.transform.hidden_layer.0.'):\n",
        "        new_key = 'transform.0.' + key.split('.', 4)[-1]\n",
        "    else:\n",
        "        new_key = key\n",
        "    new_state_dict[new_key] = state_dict[key]\n",
        "\n",
        "# Исправление размера classifier.bias\n",
        "if new_state_dict['classifier.bias'].shape == torch.Size([3994, 1]):\n",
        "    new_state_dict['classifier.bias'] = new_state_dict['classifier.bias'].squeeze()\n",
        "\n",
        "model.load_state_dict(new_state_dict, strict=False)\n",
        "model.eval()  # Перевод модели в режим предсказания\n",
        "model.cuda()  # Перенос модели на GPU\n",
        "\n",
        "# Преобразование текста в тензор\n",
        "class Text2Tensor:\n",
        "    def __init__(self, embeddings, padding_idx=0, max_len=100):\n",
        "        self.embeddings = embeddings\n",
        "        self.word_to_index = {str(i): i for i in range(embeddings.shape[0])}\n",
        "        self.padding_idx = padding_idx\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def text_to_sequence(self, text):\n",
        "        sequence = [self.word_to_index.get(word, self.padding_idx) for word in text.split()]\n",
        "        return sequence\n",
        "\n",
        "    def pad_sequence(self, sequence):\n",
        "        if len(sequence) > self.max_len:\n",
        "            return sequence[:self.max_len]\n",
        "        else:\n",
        "            return sequence + [self.padding_idx] * (self.max_len - len(sequence))\n",
        "\n",
        "    def __call__(self, text):\n",
        "        sequence = self.text_to_sequence(text)\n",
        "        padded_sequence = self.pad_sequence(sequence)\n",
        "        return torch.tensor(padded_sequence, dtype=torch.long)\n",
        "\n",
        "text2tensor = Text2Tensor(embedding_matrix, padding_idx=0, max_len=100)\n",
        "\n",
        "title = \"Т-образный тройник\"\n",
        "\n",
        "# Преобразование заголовка в тензор\n",
        "title_tensor = text2tensor(title)\n",
        "title_tensor = title_tensor.unsqueeze(0).cuda()  # Добавление размерности для батча и перенос на GPU\n",
        "\n",
        "# Предсказание\n",
        "with torch.no_grad():\n",
        "    output = model(title_tensor)\n",
        "    predicted_labels = torch.topk(output, k=5, dim=1)\n",
        "    print(predicted_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Uc6cV6fxTBL"
      },
      "source": [
        "^ при замене заголовка вывод не меняется^"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "FAJOrAYrxSpK",
        "outputId": "e2c08f56-2596-4f99-9743-a8f40f679948"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'embedding_layer'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-ba2e9755022c>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0membedding_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mCorrectAstecModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'embedding_layer'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from embedding_layer.py import Embedding\n",
        "\n",
        "class CorrectAstecModel(nn.Module):\n",
        "    def __init__(self, embedding_matrix, num_labels):\n",
        "        super(CorrectAstecModel, self).__init__()\n",
        "        self.embedding = Embedding.from_pretrained(embedding_matrix, padding_idx=0, sparse=True)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.transform = nn.Sequential(\n",
        "            nn.Linear(embedding_matrix.shape[1], embedding_matrix.shape[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5)\n",
        "        )\n",
        "        self.classifier = nn.Linear(embedding_matrix.shape[1], num_labels + 1)  # Учитываем padding_idx = 3993\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.transform(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Загрузка эмбеддингов\n",
        "embeddings_path = '/content/work_directory/data/EURLex-4K/fasttextB_embeddings_300d.npy'\n",
        "embeddings = np.load(embeddings_path, allow_pickle=True)\n",
        "\n",
        "# Исправление размера эмбеддингов, если необходимо\n",
        "if embeddings.shape[0] == 40000:\n",
        "    embeddings = np.vstack((embeddings, np.zeros((1, embeddings.shape[1]))))  # Добавляем фиктивную запись\n",
        "\n",
        "embedding_matrix = torch.tensor(embeddings, dtype=torch.float)\n",
        "\n",
        "# Параметры модели\n",
        "num_labels = 3993  # Количество меток\n",
        "\n",
        "# Создание экземпляра модели\n",
        "model = CorrectAstecModel(embedding_matrix, num_labels)\n",
        "\n",
        "# Загрузка параметров модели из state_dict\n",
        "model_path = '/content/work_directory/models/DeepXML/Astec/EURLex-4K/v_0_108/reranker/model_network.pkl'\n",
        "state_dict = torch.load(model_path, map_location='cuda:0')\n",
        "\n",
        "# Корректировка ключей в state_dict\n",
        "new_state_dict = {}\n",
        "for key in state_dict.keys():\n",
        "    if key == 'transform.transform.embeddings.weight':\n",
        "        new_key = 'embedding.weight'\n",
        "    elif key.startswith('transform_fine.transform.hidden_layer.0.'):\n",
        "        new_key = 'transform.0.' + key.split('.', 4)[-1]\n",
        "    else:\n",
        "        new_key = key\n",
        "    new_state_dict[new_key] = state_dict[key]\n",
        "\n",
        "# Исправление размера classifier.bias\n",
        "if new_state_dict['classifier.bias'].shape == torch.Size([3994, 1]):\n",
        "    new_state_dict['classifier.bias'] = new_state_dict['classifier.bias'].squeeze()\n",
        "\n",
        "model.load_state_dict(new_state_dict, strict=False)\n",
        "model.eval()  # Перевод модели в режим предсказания\n",
        "model.cuda()  # Перенос модели на GPU\n",
        "\n",
        "# Преобразование текста в тензор\n",
        "title = \"newbort retriver\"\n",
        "preprocessed_title = preprocess_title(title)\n",
        "title_tensor = embedding_layer(preprocessed_title)\n",
        "\n",
        "# Предсказание\n",
        "with torch.no_grad():\n",
        "    output = model(title_tensor)\n",
        "    predicted_labels = torch.topk(output, k=5, dim=1)\n",
        "    print(predicted_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcjPINBbt5Pe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "756fdf9a-b7a5-43d8-e926-1bf34d5b227f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for CorrectAstecModel:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([3993, 300]) from checkpoint, the shape in current model is torch.Size([3994, 300]).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-c2d8cde73868>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# Загрузка скорректированного state_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Перевод модели в режим предсказания\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Перенос модели на GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2189\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2190\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2191\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CorrectAstecModel:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([3993, 300]) from checkpoint, the shape in current model is torch.Size([3994, 300])."
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "class CorrectAstecModel(nn.Module):\n",
        "    def __init__(self, embedding_matrix, num_labels):\n",
        "        super(CorrectAstecModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag.from_pretrained(embedding_matrix, padding_idx=0, sparse=True)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.transform = nn.Sequential(\n",
        "            nn.Linear(embedding_matrix.shape[1], embedding_matrix.shape[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5)\n",
        "        )\n",
        "        self.classifier = nn.Linear(embedding_matrix.shape[1], num_labels + 1)  # Учитываем padding_idx = 3993\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.transform(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Загрузка эмбеддингов\n",
        "embeddings_path = '/content/work_directory/data/EURLex-4K/fasttextB_embeddings_300d.npy'\n",
        "embeddings = np.load(embeddings_path, allow_pickle=True)\n",
        "\n",
        "# Исправление размера эмбеддингов, если необходимо\n",
        "if embeddings.shape[0] == 40000:\n",
        "    embeddings = np.vstack((embeddings, np.zeros((1, embeddings.shape[1]))))  # Добавляем фиктивную запись\n",
        "\n",
        "embedding_matrix = torch.tensor(embeddings, dtype=torch.float)\n",
        "\n",
        "# Параметры модели\n",
        "num_labels = 3993  # Количество меток\n",
        "\n",
        "# Создание экземпляра модели\n",
        "model = CorrectAstecModel(embedding_matrix, num_labels)\n",
        "\n",
        "# Загрузка параметров модели из state_dict\n",
        "model_path = '/content/work_directory/models/DeepXML/Astec/EURLex-4K/v_0_108/reranker/model_network.pkl'\n",
        "state_dict = torch.load(model_path, map_location='cuda:0')\n",
        "\n",
        "# Корректировка ключей в state_dict\n",
        "new_state_dict = {}\n",
        "for key in state_dict.keys():\n",
        "    if key == 'transform.transform.embeddings.weight':\n",
        "        new_key = 'embedding.weight'\n",
        "    elif key.startswith('transform_fine.transform.hidden_layer.0.'):\n",
        "        new_key = 'transform.0.' + key.split('.', 4)[-1]\n",
        "    else:\n",
        "        new_key = key\n",
        "    new_state_dict[new_key] = state_dict[key]\n",
        "\n",
        "# Исправление размера classifier.bias и classifier.weight\n",
        "model.classifier = nn.Linear(embedding_matrix.shape[1], num_labels + 1, bias=True)\n",
        "if new_state_dict['classifier.bias'].shape == torch.Size([3994, 1]):\n",
        "    new_state_dict['classifier.bias'] = new_state_dict['classifier.bias'].squeeze()\n",
        "if new_state_dict['classifier.weight'].shape == torch.Size([3994, 300]):\n",
        "    new_state_dict['classifier.weight'] = new_state_dict['classifier.weight'][:3993, :]\n",
        "\n",
        "# Загрузка скорректированного state_dict\n",
        "model.load_state_dict(new_state_dict, strict=False)\n",
        "model.eval()  # Перевод модели в режим предсказания\n",
        "model.cuda()  # Перенос модели на GPU\n",
        "\n",
        "# Преобразование текста в тензор\n",
        "class Text2Tensor:\n",
        "    def __init__(self, embeddings, padding_idx=0, max_len=100):\n",
        "        self.embeddings = embeddings\n",
        "        self.word_to_index = {str(i): i for i in range(embeddings.shape[0])}\n",
        "        self.padding_idx = padding_idx\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def text_to_sequence(self, text):\n",
        "        sequence = [self.word_to_index.get(word, self.padding_idx) for word in text.split()]\n",
        "        return sequence\n",
        "\n",
        "    def pad_sequence(self, sequence):\n",
        "        if len(sequence) > self.max_len:\n",
        "            return sequence[:self.max_len]\n",
        "        else:\n",
        "            return sequence + [self.padding_idx] * (self.max_len - len(sequence))\n",
        "\n",
        "    def __call__(self, text):\n",
        "        sequence = self.text_to_sequence(text)\n",
        "        padded_sequence = self.pad_sequence(sequence)\n",
        "        return torch.tensor(padded_sequence, dtype=torch.long)\n",
        "\n",
        "text2tensor = Text2Tensor(embedding_matrix, padding_idx=0, max_len=100)\n",
        "\n",
        "def predict_single(title):\n",
        "    # Преобразование заголовка в тензор\n",
        "    title_tensor = text2tensor(title)\n",
        "    title_tensor = title_tensor.unsqueeze(0).cuda()  # Добавление размерности для батча и перенос на GPU\n",
        "\n",
        "    # Предсказание\n",
        "    with torch.no_grad():\n",
        "        output = model(title_tensor)\n",
        "        probabilities = torch.sigmoid(output)  # Применение сигмоидной функции к выходу\n",
        "        topk_prob, topk_indices = torch.topk(probabilities, k=5, dim=1)\n",
        "        return topk_indices.cpu().numpy(), topk_prob.cpu().numpy()\n",
        "\n",
        "# Пример использования\n",
        "title = \"newbort retriver\"\n",
        "predicted_labels, predicted_probabilities = predict_single(title)\n",
        "print(\"Predicted Labels:\", predicted_labels)\n",
        "print(\"Predicted Probabilities:\", predicted_probabilities)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "class CorrectAstecModel(nn.Module):\n",
        "    def __init__(self, embedding_matrix, num_labels):\n",
        "        super(CorrectAstecModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag.from_pretrained(embedding_matrix, padding_idx=0, sparse=True)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.transform = nn.Sequential(\n",
        "            nn.Linear(embedding_matrix.shape[1], embedding_matrix.shape[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5)\n",
        "        )\n",
        "        self.classifier = nn.Linear(embedding_matrix.shape[1], num_labels)  # Учитываем padding_idx = 3993\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.transform(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Загрузка эмбеддингов\n",
        "embeddings_path = '/content/work_directory/data/EURLex-4K/fasttextB_embeddings_300d.npy'\n",
        "embeddings = np.load(embeddings_path, allow_pickle=True)\n",
        "\n",
        "# Исправление размера эмбеддингов, если необходимо\n",
        "if embeddings.shape[0] == 40000:\n",
        "    embeddings = np.vstack((embeddings, np.zeros((1, embeddings.shape[1]))))  # Добавляем фиктивную запись\n",
        "\n",
        "embedding_matrix = torch.tensor(embeddings, dtype=torch.float)\n",
        "\n",
        "# Параметры модели\n",
        "num_labels = 3993  # Количество меток\n",
        "\n",
        "# Создание экземпляра модели\n",
        "model = CorrectAstecModel(embedding_matrix, num_labels)\n",
        "\n",
        "# Загрузка параметров модели из state_dict\n",
        "model_path = '/content/work_directory/models/DeepXML/Astec/EURLex-4K/v_0_108/reranker/model_network.pkl'\n",
        "state_dict = torch.load(model_path, map_location='cuda:0')\n",
        "\n",
        "# Корректировка ключей в state_dict\n",
        "new_state_dict = {}\n",
        "for key in state_dict.keys():\n",
        "    if key == 'transform.transform.embeddings.weight':\n",
        "        new_key = 'embedding.weight'\n",
        "    elif key.startswith('transform_fine.transform.hidden_layer.0.'):\n",
        "        new_key = 'transform.0.' + key.split('.', 4)[-1]\n",
        "    else:\n",
        "        new_key = key\n",
        "    new_state_dict[new_key] = state_dict[key]\n",
        "\n",
        "# Исправление размера classifier.bias и classifier.weight\n",
        "if new_state_dict['classifier.bias'].shape == torch.Size([3994, 1]):\n",
        "    new_state_dict['classifier.bias'] = new_state_dict['classifier.bias'].squeeze()[:3993]\n",
        "if new_state_dict['classifier.weight'].shape == torch.Size([3994, 300]):\n",
        "    new_state_dict['classifier.weight'] = new_state_dict['classifier.weight'][:3993, :]\n",
        "\n",
        "# Загрузка скорректированного state_dict\n",
        "model.load_state_dict(new_state_dict, strict=False)\n",
        "model.eval()  # Перевод модели в режим предсказания\n",
        "model.cuda()  # Перенос модели на GPU\n",
        "\n",
        "# Преобразование текста в тензор\n",
        "class Text2Tensor:\n",
        "    def __init__(self, embeddings, padding_idx=0, max_len=100):\n",
        "        self.embeddings = embeddings\n",
        "        self.word_to_index = {str(i): i for i in range(embeddings.shape[0])}\n",
        "        self.padding_idx = padding_idx\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def text_to_sequence(self, text):\n",
        "        sequence = [self.word_to_index.get(word, self.padding_idx) for word in text.split()]\n",
        "        return sequence\n",
        "\n",
        "    def pad_sequence(self, sequence):\n",
        "        if len(sequence) > self.max_len:\n",
        "            return sequence[:self.max_len]\n",
        "        else:\n",
        "            return sequence + [self.padding_idx] * (self.max_len - len(sequence))\n",
        "\n",
        "    def __call__(self, text):\n",
        "        sequence = self.text_to_sequence(text)\n",
        "        padded_sequence = self.pad_sequence(sequence)\n",
        "        return torch.tensor(padded_sequence, dtype=torch.long)\n",
        "\n",
        "text2tensor = Text2Tensor(embedding_matrix, padding_idx=0, max_len=100)\n",
        "\n",
        "def predict_single(title):\n",
        "    # Преобразование заголовка в тензор\n",
        "    title_tensor = text2tensor(title)\n",
        "    title_tensor = title_tensor.unsqueeze(0).cuda()  # Добавление размерности для батча и перенос на GPU\n",
        "\n",
        "    # Предсказание\n",
        "    with torch.no_grad():\n",
        "        output = model(title_tensor)\n",
        "        probabilities = torch.sigmoid(output)  # Применение сигмоидной функции к выходу\n",
        "        topk_prob, topk_indices = torch.topk(probabilities, k=5, dim=1)\n",
        "        return topk_indices.cpu().numpy(), topk_prob.cpu().numpy()\n",
        "\n",
        "# Пример использования\n",
        "title = \"toy car\"\n",
        "predicted_labels, predicted_probabilities = predict_single(title)\n",
        "print(\"Predicted Labels:\", predicted_labels)\n",
        "print(\"Predicted Probabilities:\", predicted_probabilities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "zvmoDM63DGCX",
        "outputId": "3b4bb759-fa46-469b-f4fe-46eec54e4658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/work_directory/data/EURLex-4K/fasttextB_embeddings_300d.npy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2b774e45a6f4>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Загрузка эмбеддингов\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0membeddings_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/work_directory/data/EURLex-4K/fasttextB_embeddings_300d.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Исправление размера эмбеддингов, если необходимо\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/work_directory/data/EURLex-4K/fasttextB_embeddings_300d.npy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python /content/work_directory/programs/deepxml/deepxml/runner.py DeepXML /content/work_directory/programs/deepxml/deepxml/runner.py 42 predict_single 108\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mzb7-DLylYF5",
        "outputId": "22faa759-c58a-4e0c-f694-cb2ba2ecea42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/work_directory/programs/deepxml/deepxml/runner.py\", line 466, in <module>\n",
            "    config=json.load(open(config)))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'predict_single/DeepXML/42.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ./run_main.sh 0 DeepXML EURLex-4K 0 108"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ykreZTHohxc",
        "outputId": "cc678a58-0ce0-4ae4-d9f2-452620fbde99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using existing data for surrogate task!\n",
            "\n",
            "Setting the seed value: 108\n",
            "Initialized token embeddings!\n",
            "Model parameters:  Namespace(dataset='EURLex-4K', data_dir='/content/work_directory/data', model_dir='/content/work_directory/models/DeepXML/Astec/EURLex-4K/v_0_108/surrogate', result_dir='/content/work_directory/results/DeepXML/Astec/EURLex-4K/v_0_108/surrogate', model_fname='model', pred_fname='predictions', trn_feat_fname='trn_X_Xf.txt', val_feat_fname='tst_X_Xf.txt', tst_feat_fname='tst_X_Xf.txt', trn_label_fname='trn_X_Y.txt', val_label_fname='tst_X_Y.txt', feature_type='sparse', tst_label_fname='tst_X_Y.txt', arch='/content/work_directory/programs/deepxml/deepxml/run_scripts/Astec.json', learning_rate=0.01, surrogate_mapping='/content/work_directory/data/EURLex-4K/deepxml.Astec/1024.108/surrogate_mapping.txt', dlr_step=14, last_epoch=0, shortlist_method='static', model_method='full', ns_method='kcentroid', ann_method='hnsw', seed=108, top_k=100, num_workers=6, ann_threads=12, num_clf_partitions=1, label_indices=None, feature_indices=None, efC=300, num_nbrs=300, efS=300, M=100, retrain_hnsw_after=1, num_labels=1024, vocabulary_dims=40000, padding_idx=0, out_fname='out', dlr_factor=0.5, momentum=0.9, weight_decay=0.0, dropout=0.5, optim='Adam', embedding_dims=300, embeddings='fasttextB_embeddings_300d.npy', validate_after=5, num_epochs=20, batch_size=255, num_centroids=1, beta=0.3, res_init='eye', label_padding_index=None, mode='train', init='token_embeddings', keep_invalid=False, freeze_intermediate=False, use_shortlist=False, save_intermediate=True, use_pretrained_shortlist=False, validate=True, bias=True, shuffle=True, devices=['cuda:0'], normalize=True, nbn_rel=False, update_shortlist=False, huge_dataset=False, use_intermediate_for_shorty=False, get_only=['knn', 'clf', 'combined'], A=0.55, B=1.5, use_reranker=True, surrogate_threshold=1024, surrogate_method=1, save_predictions=True)\n",
            "\n",
            "Model configuration:  Transform(\n",
            "  (transform): Astec(\n",
            "    (embeddings): Embedding(40001, 300, cuda:0, reduction=sum, padding_idx=0, sparse=True)\n",
            "    (relu): ReLU()\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            ")\n",
            "(Transform fine): Transform(\n",
            "  (transform): Residual(\n",
            "    (hidden_layer): Sequential(\n",
            "      (0): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "(Classifier): Linear(300, 1024, cuda:0, bias=True)\n",
            "\n",
            "Loading training data.\n",
            "Surrogate mapping is not None, mapping labels\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Loading validation data.\n",
            "/usr/local/lib/python3.10/dist-packages/xclib-0.97-py3.10-linux-x86_64.egg/xclib/data/data_utils.py:263: UserWarning: Header mis-match from inferred shape!\n",
            "  warnings.warn(\"Header mis-match from inferred shape!\")\n",
            "Surrogate mapping is not None, mapping labels\n",
            "loss: 0.03087: 100% 61/61 [00:05<00:00, 11.51it/s]\n",
            "Epoch: 0, loss: 0.057775, time: 5.30 sec\n",
            "100% 15/15 [00:01<00:00, 10.17it/s]\n",
            "Model saved after epoch: 0\n",
            "P@1: 17.20, loss: 0.030005, time: 1.48 sec\n",
            "  0% 0/61 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss: 0.02645: 100% 61/61 [00:04<00:00, 12.69it/s]\n",
            "Epoch: 1, loss: 0.028263, time: 4.81 sec\n",
            "loss: 0.02311: 100% 61/61 [00:05<00:00, 11.42it/s]\n",
            "Epoch: 2, loss: 0.024103, time: 5.34 sec\n",
            "loss: 0.02052: 100% 61/61 [00:08<00:00,  7.50it/s]\n",
            "Epoch: 3, loss: 0.021435, time: 8.13 sec\n",
            "loss: 0.01878: 100% 61/61 [00:04<00:00, 13.10it/s]\n",
            "Epoch: 4, loss: 0.019512, time: 4.66 sec\n",
            "loss: 0.01726: 100% 61/61 [00:05<00:00, 12.00it/s]\n",
            "Epoch: 5, loss: 0.018067, time: 5.08 sec\n",
            "100% 15/15 [00:02<00:00,  6.88it/s]\n",
            "Model saved after epoch: 5\n",
            "P@1: 71.93, loss: 0.017261, time: 2.19 sec\n",
            "loss: 0.01682: 100% 61/61 [00:05<00:00, 12.20it/s]\n",
            "Epoch: 6, loss: 0.016875, time: 5.00 sec\n",
            "loss: 0.01551: 100% 61/61 [00:04<00:00, 13.42it/s]\n",
            "Epoch: 7, loss: 0.015862, time: 4.55 sec\n",
            "loss: 0.01458: 100% 61/61 [00:06<00:00,  8.83it/s]\n",
            "Epoch: 8, loss: 0.014988, time: 6.91 sec\n",
            "loss: 0.01428: 100% 61/61 [00:04<00:00, 13.06it/s]\n",
            "Epoch: 9, loss: 0.014237, time: 4.67 sec\n",
            "loss: 0.01274: 100% 61/61 [00:04<00:00, 13.41it/s]\n",
            "Epoch: 10, loss: 0.013514, time: 4.55 sec\n",
            "100% 15/15 [00:01<00:00, 11.22it/s]\n",
            "Model saved after epoch: 10\n",
            "P@1: 78.45, loss: 0.015238, time: 1.34 sec\n",
            "loss: 0.01331: 100% 61/61 [00:07<00:00,  7.90it/s]\n",
            "Epoch: 11, loss: 0.012906, time: 7.73 sec\n",
            "loss: 0.01194: 100% 61/61 [00:04<00:00, 13.01it/s]\n",
            "Epoch: 12, loss: 0.012325, time: 4.69 sec\n",
            "loss: 0.01270: 100% 61/61 [00:04<00:00, 13.50it/s]\n",
            "Epoch: 13, loss: 0.011841, time: 4.52 sec\n",
            "Adjusted learning rate to: 0.005\n",
            "loss: 0.01116: 100% 61/61 [00:06<00:00,  8.80it/s]\n",
            "Epoch: 14, loss: 0.011123, time: 6.94 sec\n",
            "loss: 0.01143: 100% 61/61 [00:04<00:00, 13.10it/s]\n",
            "Epoch: 15, loss: 0.010823, time: 4.66 sec\n",
            "100% 15/15 [00:01<00:00, 11.72it/s]\n",
            "Model saved after epoch: 15\n",
            "Purging network checkpoint: checkpoint_net_1.pkl\n",
            "P@1: 79.05, loss: 0.014922, time: 1.28 sec\n",
            "loss: 0.01124: 100% 61/61 [00:04<00:00, 12.22it/s]\n",
            "Epoch: 16, loss: 0.010516, time: 4.99 sec\n",
            "loss: 0.01050: 100% 61/61 [00:07<00:00,  7.97it/s]\n",
            "Epoch: 17, loss: 0.010302, time: 7.66 sec\n",
            "loss: 0.01009: 100% 61/61 [00:04<00:00, 13.49it/s]\n",
            "Epoch: 18, loss: 0.010050, time: 4.52 sec\n",
            "loss: 0.00994: 100% 61/61 [00:04<00:00, 13.39it/s]\n",
            "Epoch: 19, loss: 0.009790, time: 4.56 sec\n",
            "Purging network checkpoint: checkpoint_net_6.pkl\n",
            "Training time: 109.28 sec, Validation time: 6.29 sec, Shortlist time: 0.00 sec, Model size: 47.30 MB\n",
            "Saving model at: /content/work_directory/models/DeepXML/Astec/EURLex-4K/v_0_108/surrogate/model_network.pkl\n",
            "\n",
            "Setting the seed value: 108\n",
            "Model parameters:  Namespace(dataset='EURLex-4K', data_dir='/content/work_directory/data', model_dir='/content/work_directory/models/DeepXML/Astec/EURLex-4K/v_0_108/surrogate', result_dir='/content/work_directory/results/DeepXML/Astec/EURLex-4K/v_0_108/surrogate', model_fname='model', pred_fname='predictions', trn_feat_fname='trn_X_Xf.txt', val_feat_fname='tst_X_Xf.txt', tst_feat_fname='tst_X_Xf.txt', trn_label_fname='trn_X_Y.txt', val_label_fname='tst_X_Y.txt', feature_type='sparse', tst_label_fname='tst_X_Y.txt', arch='/content/work_directory/programs/deepxml/deepxml/run_scripts/Astec.json', learning_rate=0.01, surrogate_mapping='/content/work_directory/data/EURLex-4K/deepxml.Astec/1024.108/surrogate_mapping.txt', dlr_step=14, last_epoch=0, shortlist_method='static', model_method='full', ns_method='kcentroid', ann_method='hnsw', seed=108, top_k=100, num_workers=6, ann_threads=12, num_clf_partitions=1, label_indices=None, feature_indices=None, efC=300, num_nbrs=300, efS=300, M=100, retrain_hnsw_after=1, num_labels=1024, vocabulary_dims=40000, padding_idx=0, out_fname='out', dlr_factor=0.5, momentum=0.9, weight_decay=0.0, dropout=0.5, optim='Adam', embedding_dims=300, embeddings='fasttextB_embeddings_300d.npy', validate_after=5, num_epochs=20, batch_size=255, num_centroids=1, beta=0.3, res_init='eye', label_padding_index=None, mode='predict', init='token_embeddings', keep_invalid=False, freeze_intermediate=False, use_shortlist=False, save_intermediate=True, use_pretrained_shortlist=False, validate=True, bias=True, shuffle=True, devices=['cuda:0'], normalize=True, nbn_rel=False, update_shortlist=False, huge_dataset=False, use_intermediate_for_shorty=False, get_only=['knn', 'clf', 'combined'], A=0.55, B=1.5, use_reranker=True, surrogate_threshold=1024, surrogate_method=1, save_predictions=True)\n",
            "\n",
            "Model configuration:  Transform(\n",
            "  (transform): Astec(\n",
            "    (embeddings): Embedding(40001, 300, cuda:0, reduction=sum, padding_idx=0, sparse=True)\n",
            "    (relu): ReLU()\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            ")\n",
            "(Transform fine): Transform(\n",
            "  (transform): Residual(\n",
            "    (hidden_layer): Sequential(\n",
            "      (0): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "(Classifier): Linear(300, 1024, cuda:0, bias=True)\n",
            "\n",
            "Shapes are fine, Not padding again.\n",
            "/usr/local/lib/python3.10/dist-packages/xclib-0.97-py3.10-linux-x86_64.egg/xclib/data/data_utils.py:263: UserWarning: Header mis-match from inferred shape!\n",
            "  warnings.warn(\"Header mis-match from inferred shape!\")\n",
            "Surrogate mapping is not None, mapping labels\n",
            "100% 15/15 [00:02<00:00,  7.01it/s]\n",
            "Prediction time (total): 2.15 sec.,Prediction time (per sample): 0.56 msec., P@k(%): (clf): 79.97,72.51,66.13,60.10,54.77\n",
            "\n",
            "\n",
            "\n",
            "Labels:   (0, 9)\t-5.4312787\n",
            "  (0, 10)\t-6.362383\n",
            "  (0, 16)\t-5.7634993\n",
            "  (0, 20)\t-6.752306\n",
            "  (0, 25)\t-7.023059\n",
            "  (0, 26)\t-6.6417065\n",
            "  (0, 44)\t-6.985428\n",
            "  (0, 46)\t-7.244224\n",
            "  (0, 60)\t-7.3881345\n",
            "  (0, 84)\t-7.2943625\n",
            "  (0, 85)\t-6.178422\n",
            "  (0, 90)\t-7.2251625\n",
            "  (0, 92)\t-3.3020792\n",
            "  (0, 95)\t-3.4170194\n",
            "  (0, 124)\t-5.228079\n",
            "  (0, 129)\t-6.986023\n",
            "  (0, 138)\t-1.3900588\n",
            "  (0, 140)\t-7.134613\n",
            "  (0, 150)\t-6.095767\n",
            "  (0, 159)\t-7.3634696\n",
            "  (0, 191)\t-6.2518177\n",
            "  (0, 235)\t-7.279466\n",
            "  (0, 249)\t-6.4595118\n",
            "  (0, 264)\t-2.8494356\n",
            "  (0, 274)\t-5.3059015\n",
            "  :\t:\n",
            "  (3808, 821)\t-6.249069\n",
            "  (3808, 823)\t-4.8584013\n",
            "  (3808, 831)\t-6.5179057\n",
            "  (3808, 836)\t-6.2530923\n",
            "  (3808, 850)\t-5.448798\n",
            "  (3808, 852)\t-5.6164427\n",
            "  (3808, 853)\t-6.2411213\n",
            "  (3808, 856)\t-4.900614\n",
            "  (3808, 865)\t-6.6574783\n",
            "  (3808, 872)\t-6.2701654\n",
            "  (3808, 874)\t-3.3633733\n",
            "  (3808, 904)\t-5.3555007\n",
            "  (3808, 914)\t-6.579624\n",
            "  (3808, 923)\t-6.474184\n",
            "  (3808, 932)\t-5.7233887\n",
            "  (3808, 976)\t-5.569589\n",
            "  (3808, 979)\t-6.124804\n",
            "  (3808, 981)\t-5.420228\n",
            "  (3808, 992)\t-4.3725553\n",
            "  (3808, 997)\t-5.600917\n",
            "  (3808, 1003)\t-6.3494964\n",
            "  (3808, 1012)\t-6.183085\n",
            "  (3808, 1013)\t-3.1300652\n",
            "  (3808, 1016)\t-5.4467983\n",
            "  (3808, 1022)\t-5.6995974\n",
            "\n",
            "Setting the seed value: 108\n",
            "Freezing intermediate model parameters!\n",
            "Loading the intermediate representation.\n",
            "Model parameters:  Namespace(dataset='EURLex-4K', data_dir='/content/work_directory/data', model_dir='/content/work_directory/models/DeepXML/Astec/EURLex-4K/v_0_108/extreme', result_dir='/content/work_directory/results/DeepXML/Astec/EURLex-4K/v_0_108/extreme', model_fname='model', pred_fname='predictions', trn_feat_fname='trn_X_Xf.txt', val_feat_fname='tst_X_Xf.txt', tst_feat_fname='tst_X_Xf.txt', trn_label_fname='trn_X_Y.txt', val_label_fname='tst_X_Y.txt', feature_type='sparse', tst_label_fname='tst_X_Y.txt', arch='/content/work_directory/programs/deepxml/deepxml/run_scripts/Astec.json', learning_rate=0.007, surrogate_mapping=None, dlr_step=14, last_epoch=0, shortlist_method='hybrid', model_method='shortlist', ns_method='ensemble', ann_method='hnsw', seed=108, top_k=100, num_workers=6, ann_threads=18, num_clf_partitions=1, label_indices=None, feature_indices=None, efC=300, num_nbrs=500, efS=400, M=100, retrain_hnsw_after=1, num_labels=3786, vocabulary_dims=40000, padding_idx=0, out_fname='out', dlr_factor=0.5, momentum=0.9, weight_decay=0.0, dropout=0.5, optim='Adam', embedding_dims=300, embeddings='fasttextB_embeddings_300d.npy', validate_after=5, num_epochs=20, batch_size=255, num_centroids=1, beta=0.5, res_init='eye', label_padding_index=3786, mode='train', init='intermediate', keep_invalid=False, freeze_intermediate=True, use_shortlist=True, save_intermediate=True, use_pretrained_shortlist=False, validate=True, bias=True, shuffle=True, devices=['cuda:0'], normalize=True, nbn_rel=False, update_shortlist=False, huge_dataset=False, use_intermediate_for_shorty=True, get_only=['knn', 'clf', 'combined'], A=0.55, B=1.5, use_reranker=True, surrogate_threshold=1024, surrogate_method=1, save_predictions=True)\n",
            "\n",
            "Model configuration:  Transform(\n",
            "  (transform): Astec(\n",
            "    (embeddings): Embedding(40001, 300, cuda:0, reduction=sum, padding_idx=0, sparse=True)\n",
            "    (relu): ReLU()\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            ")\n",
            "(Transform fine): Transform(\n",
            "  (transform): Residual(\n",
            "    (hidden_layer): Sequential(\n",
            "      (0): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "(Classifier): SparseLinear(300, 3787, cuda:0, bias=True, padding_idx=3786, sparse=True)\n",
            "\n",
            "Loading training data.\n",
            "Computing and reusing intermediate document embeddings to save computations.\n",
            "Using the default encoder.\n",
            "100% 16/16 [00:03<00:00,  4.55it/s]\n",
            "Loading validation data.\n",
            "Updating shortlist at epoch: 0\n",
            "Using pre-trained embeddings for shortlist.\n",
            "\n",
            "0%   10   20   30   40   50   60   70   80   90   100%\n",
            "|----|----|----|----|----|----|----|----|----|----|\n",
            "***************************************************\n",
            "\n",
            "0%   10   20   30   40   50   60   70   80   90   100%\n",
            "|----|----|----|----|----|----|----|----|----|----|\n",
            "***************************************************\n",
            "Using the default encoder.\n",
            "100% 4/4 [00:01<00:00,  3.29it/s]\n",
            "ANN train time: 14.16 sec\n",
            "loss: 23.04867: 100% 61/61 [00:05<00:00, 12.03it/s]\n",
            "Epoch: 0, loss: 41.214491, time: 5.07 sec\n",
            "100% 15/15 [00:02<00:00,  5.63it/s]\n",
            "Model saved after epoch: 0\n",
            "P@k (knn): 74.09,64.36,56.45,50.17,45.37 (clf): 59.46,49.97,43.29,38.11,34.11 (ens): 65.56,56.59,49.89,45.44,41.29, loss: 21.740146, time: 2.81 sec\n",
            "loss: 18.01369: 100% 61/61 [00:07<00:00,  8.37it/s]\n",
            "Epoch: 1, loss: 20.319263, time: 7.29 sec\n",
            "loss: 15.69319: 100% 61/61 [00:05<00:00, 11.93it/s]\n",
            "Epoch: 2, loss: 16.681488, time: 5.12 sec\n",
            "loss: 13.69442: 100% 61/61 [00:06<00:00,  9.57it/s]\n",
            "Epoch: 3, loss: 14.267728, time: 6.38 sec\n",
            "loss: 11.33993: 100% 61/61 [00:06<00:00,  8.79it/s]\n",
            "Epoch: 4, loss: 12.502282, time: 6.94 sec\n",
            "loss: 10.38151: 100% 61/61 [00:04<00:00, 12.35it/s]\n",
            "Epoch: 5, loss: 11.084102, time: 4.94 sec\n",
            "100% 15/15 [00:01<00:00,  8.10it/s]\n",
            "Model saved after epoch: 5\n",
            "P@k (knn): 74.09,64.36,56.45,50.17,45.37 (clf): 80.02,71.78,64.76,58.89,53.36 (ens): 80.41,71.99,65.01,59.16,53.49, loss: 14.123817, time: 1.96 sec\n",
            "loss: 8.50638: 100% 61/61 [00:08<00:00,  7.48it/s]\n",
            "Epoch: 6, loss: 9.659092, time: 8.16 sec\n",
            "loss: 8.34084: 100% 61/61 [00:05<00:00, 11.46it/s]\n",
            "Epoch: 7, loss: 8.395826, time: 5.32 sec\n",
            "loss: 7.25055: 100% 61/61 [00:04<00:00, 12.30it/s]\n",
            "Epoch: 8, loss: 7.605970, time: 4.96 sec\n",
            "loss: 7.57730: 100% 61/61 [00:08<00:00,  7.19it/s]\n",
            "Epoch: 9, loss: 7.064211, time: 8.48 sec\n",
            "loss: 6.79219: 100% 61/61 [00:05<00:00, 11.87it/s]\n",
            "Epoch: 10, loss: 6.616141, time: 5.14 sec\n",
            "100% 15/15 [00:01<00:00,  8.04it/s]\n",
            "Model saved after epoch: 10\n",
            "P@k (knn): 74.09,64.36,56.45,50.17,45.37 (clf): 80.78,73.16,66.68,60.46,55.16 (ens): 81.07,73.18,66.76,60.68,55.42, loss: 13.737066, time: 1.97 sec\n",
            "loss: 6.62265: 100% 61/61 [00:06<00:00,  9.56it/s]\n",
            "Epoch: 11, loss: 6.236016, time: 6.38 sec\n",
            "loss: 6.05736: 100% 61/61 [00:07<00:00,  8.50it/s]\n",
            "Epoch: 12, loss: 5.913977, time: 7.18 sec\n",
            "loss: 6.08471: 100% 61/61 [00:04<00:00, 12.26it/s]\n",
            "Epoch: 13, loss: 5.639469, time: 4.98 sec\n",
            "Adjusted learning rate to: 0.0035\n",
            "loss: 5.78596: 100% 61/61 [00:06<00:00,  9.83it/s]\n",
            "Epoch: 14, loss: 5.185656, time: 6.21 sec\n",
            "loss: 5.41574: 100% 61/61 [00:07<00:00,  8.44it/s]\n",
            "Epoch: 15, loss: 5.017645, time: 7.23 sec\n",
            "100% 15/15 [00:01<00:00,  8.07it/s]\n",
            "Model saved after epoch: 15\n",
            "Purging network checkpoint: checkpoint_net_1.pkl\n",
            "P@k (knn): 74.09,64.36,56.45,50.17,45.37 (clf): 81.07,73.21,67.20,61.31,56.14 (ens): 81.33,73.33,67.22,61.36,56.16, loss: 13.990798, time: 1.97 sec\n",
            "loss: 5.19143: 100% 61/61 [00:05<00:00, 11.54it/s]\n",
            "Epoch: 16, loss: 4.911675, time: 5.29 sec\n",
            "loss: 4.89342: 100% 61/61 [00:08<00:00,  7.30it/s]\n",
            "Epoch: 17, loss: 4.806403, time: 8.36 sec\n",
            "loss: 4.66969: 100% 61/61 [00:05<00:00, 11.95it/s]\n",
            "Epoch: 18, loss: 4.697941, time: 5.10 sec\n",
            "loss: 4.64053: 100% 61/61 [00:05<00:00, 12.01it/s]\n",
            "Epoch: 19, loss: 4.604089, time: 5.08 sec\n",
            "Purging network checkpoint: checkpoint_net_6.pkl\n",
            "Training time: 123.60 sec, Validation time: 8.70 sec, Shortlist time: 14.16 sec, Model size: 81.89 MB\n",
            "Saving model at: /content/work_directory/models/DeepXML/Astec/EURLex-4K/v_0_108/extreme/model_network.pkl\n",
            "\n",
            "Setting the seed value: 108\n",
            "Freezing intermediate model parameters!\n",
            "Model parameters:  Namespace(dataset='EURLex-4K', data_dir='/content/work_directory/data', model_dir='/content/work_directory/models/DeepXML/Astec/EURLex-4K/v_0_108/extreme', result_dir='/content/work_directory/results/DeepXML/Astec/EURLex-4K/v_0_108/extreme', model_fname='model', pred_fname='tst_predictions', trn_feat_fname='trn_X_Xf.txt', val_feat_fname='tst_X_Xf.txt', tst_feat_fname='tst_X_Xf.txt', trn_label_fname='trn_X_Y.txt', val_label_fname='tst_X_Y.txt', feature_type='sparse', tst_label_fname='tst_X_Y.txt', arch='/content/work_directory/programs/deepxml/deepxml/run_scripts/Astec.json', learning_rate=0.007, surrogate_mapping=None, dlr_step=14, last_epoch=0, shortlist_method='hybrid', model_method='shortlist', ns_method='ensemble', ann_method='hnsw', seed=108, top_k=100, num_workers=6, ann_threads=18, num_clf_partitions=1, label_indices=None, feature_indices=None, efC=300, num_nbrs=500, efS=400, M=100, retrain_hnsw_after=1, num_labels=3786, vocabulary_dims=40000, padding_idx=0, out_fname='out', dlr_factor=0.5, momentum=0.9, weight_decay=0.0, dropout=0.5, optim='Adam', embedding_dims=300, embeddings='fasttextB_embeddings_300d.npy', validate_after=5, num_epochs=20, batch_size=255, num_centroids=1, beta=0.5, res_init='eye', label_padding_index=3786, mode='predict', init='intermediate', keep_invalid=False, freeze_intermediate=True, use_shortlist=True, save_intermediate=True, use_pretrained_shortlist=False, validate=True, bias=True, shuffle=True, devices=['cuda:0'], normalize=True, nbn_rel=False, update_shortlist=False, huge_dataset=False, use_intermediate_for_shorty=True, get_only=['knn', 'clf', 'combined'], A=0.55, B=1.5, use_reranker=True, surrogate_threshold=1024, surrogate_method=1, save_predictions=True)\n",
            "\n",
            "Model configuration:  Transform(\n",
            "  (transform): Astec(\n",
            "    (embeddings): Embedding(40001, 300, cuda:0, reduction=sum, padding_idx=0, sparse=True)\n",
            "    (relu): ReLU()\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            ")\n",
            "(Transform fine): Transform(\n",
            "  (transform): Residual(\n",
            "    (hidden_layer): Sequential(\n",
            "      (0): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "(Classifier): SparseLinear(300, 3787, cuda:0, bias=True, padding_idx=3786, sparse=True)\n",
            "\n",
            "Shapes are fine, Not padding again.\n",
            "Loading test data.\n",
            "Fetching shortlist.\n",
            "Using the default encoder.\n",
            "100% 4/4 [00:01<00:00,  2.24it/s]\n",
            "100% 15/15 [00:01<00:00,  8.01it/s]\n",
            "Prediction time (total): 5.51 sec., Prediction time (per sample): 1.45 msec., P@k(%): (knn): 74.09,64.35,56.45,50.17,45.37 (clf): 80.76,73.17,67.04,60.88,55.23 (ens): 81.04,73.37,67.40,61.19,55.79\n",
            "\n",
            "\n",
            "\n",
            "Labels: {'knn': <3809x3786 sparse matrix of type '<class 'numpy.float32'>'\n",
            "\twith 380900 stored elements in Compressed Sparse Row format>, 'clf': <3809x3786 sparse matrix of type '<class 'numpy.float32'>'\n",
            "\twith 91091 stored elements in Compressed Sparse Row format>, 'ens': <3809x3786 sparse matrix of type '<class 'numpy.float32'>'\n",
            "\twith 396845 stored elements in Compressed Sparse Row format>}\n",
            "\n",
            "------------------------------\n",
            "classifier\n",
            "80.76,73.17,67.04,60.88,55.23\n",
            "80.76,74.91,70.52,66.71,64.30\n",
            "36.71,40.73,43.92,45.70,47.04\n",
            "36.71,39.69,41.95,43.25,44.21\n",
            "shortlist\n",
            "74.09,64.35,56.45,50.17,45.37\n",
            "74.09,66.57,60.75,56.60,54.39\n",
            "40.47,42.14,42.32,42.25,42.76\n",
            "40.47,41.71,41.90,41.95,42.33\n",
            "beta: 0.10\n",
            "80.78,73.43,66.90,60.62,54.74\n",
            "80.78,75.12,70.45,66.54,63.97\n",
            "40.00,43.35,45.65,47.09,48.11\n",
            "40.00,42.48,44.13,45.20,45.95\n",
            "beta: 0.20\n",
            "80.81,73.52,67.29,61.03,55.53\n",
            "80.81,75.19,70.74,66.87,64.57\n",
            "39.07,42.37,45.21,46.70,48.19\n",
            "39.07,41.51,43.51,44.64,45.65\n",
            "beta: 0.30\n",
            "80.83,73.35,67.44,61.18,55.72\n",
            "80.83,75.07,70.83,66.98,64.72\n",
            "38.52,41.93,44.95,46.50,48.05\n",
            "38.52,41.05,43.17,44.33,45.40\n",
            "beta: 0.40\n",
            "80.91,73.35,67.41,61.16,55.69\n",
            "80.91,75.08,70.82,66.97,64.70\n",
            "38.27,41.66,44.69,46.34,47.87\n",
            "38.27,40.78,42.91,44.12,45.19\n",
            "beta: 0.50\n",
            "80.97,73.31,67.38,61.14,55.76\n",
            "80.97,75.07,70.80,66.95,64.76\n",
            "38.07,41.41,44.48,46.27,47.87\n",
            "38.07,40.55,42.70,43.99,45.11\n",
            "beta: 0.60\n",
            "80.86,73.23,67.30,61.14,55.73\n",
            "80.86,74.98,70.72,66.92,64.70\n",
            "37.82,41.22,44.37,46.12,47.74\n",
            "37.82,40.34,42.55,43.82,44.94\n",
            "beta: 0.75\n",
            "80.91,73.34,67.21,61.21,55.73\n",
            "80.91,75.07,70.68,66.98,64.71\n",
            "37.44,41.10,44.22,46.06,47.64\n",
            "37.44,40.16,42.35,43.69,44.78\n",
            "beta: 0.90\n",
            "80.78,73.16,67.21,61.20,55.70\n",
            "80.78,74.90,70.64,66.94,64.65\n",
            "37.02,40.81,44.09,46.01,47.54\n",
            "37.02,39.83,42.14,43.53,44.58\n",
            "------------------------------\n",
            "\n",
            "Setting the seed value: 108\n",
            "Freezing intermediate model parameters!\n",
            "Model parameters:  Namespace(dataset='EURLex-4K', data_dir='/content/work_directory/data', model_dir='/content/work_directory/models/DeepXML/Astec/EURLex-4K/v_0_108/extreme', result_dir='/content/work_directory/results/DeepXML/Astec/EURLex-4K/v_0_108/extreme', model_fname='model', pred_fname='trn_predictions', trn_feat_fname='trn_X_Xf.txt', val_feat_fname='tst_X_Xf.txt', tst_feat_fname='trn_X_Xf.txt', trn_label_fname='trn_X_Y.txt', val_label_fname='tst_X_Y.txt', feature_type='sparse', tst_label_fname='trn_X_Y.txt', arch='/content/work_directory/programs/deepxml/deepxml/run_scripts/Astec.json', learning_rate=0.007, surrogate_mapping=None, dlr_step=14, last_epoch=0, shortlist_method='hybrid', model_method='shortlist', ns_method='ensemble', ann_method='hnsw', seed=108, top_k=100, num_workers=6, ann_threads=18, num_clf_partitions=1, label_indices=None, feature_indices=None, efC=300, num_nbrs=500, efS=400, M=100, retrain_hnsw_after=1, num_labels=3786, vocabulary_dims=40000, padding_idx=0, out_fname='out', dlr_factor=0.5, momentum=0.9, weight_decay=0.0, dropout=0.5, optim='Adam', embedding_dims=300, embeddings='fasttextB_embeddings_300d.npy', validate_after=5, num_epochs=20, batch_size=255, num_centroids=1, beta=0.5, res_init='eye', label_padding_index=3786, mode='predict', init='intermediate', keep_invalid=False, freeze_intermediate=True, use_shortlist=True, save_intermediate=True, use_pretrained_shortlist=False, validate=True, bias=True, shuffle=True, devices=['cuda:0'], normalize=True, nbn_rel=False, update_shortlist=False, huge_dataset=False, use_intermediate_for_shorty=True, get_only='clf', A=0.55, B=1.5, use_reranker=True, surrogate_threshold=1024, surrogate_method=1, save_predictions=True)\n",
            "\n",
            "Model configuration:  Transform(\n",
            "  (transform): Astec(\n",
            "    (embeddings): Embedding(40001, 300, cuda:0, reduction=sum, padding_idx=0, sparse=True)\n",
            "    (relu): ReLU()\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            ")\n",
            "(Transform fine): Transform(\n",
            "  (transform): Residual(\n",
            "    (hidden_layer): Sequential(\n",
            "      (0): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "(Classifier): SparseLinear(300, 3787, cuda:0, bias=True, padding_idx=3786, sparse=True)\n",
            "\n",
            "Shapes are fine, Not padding again.\n",
            "Loading test data.\n",
            "Fetching shortlist.\n",
            "Using the default encoder.\n",
            "100% 16/16 [00:03<00:00,  4.82it/s]\n",
            "100% 61/61 [00:06<00:00,  9.00it/s]\n",
            "Prediction time (total): 18.86 sec., Prediction time (per sample): 1.21 msec., P@k(%): (knn): 88.74,80.24,72.35,65.23,59.13 (clf): 98.81,97.64,95.65,92.04,86.32 (ens): 98.75,97.54,95.47,91.77,85.91\n",
            "\n",
            "Setting the seed value: 108\n",
            "Initialized token embeddings!\n",
            "Model parameters:  Namespace(dataset='EURLex-4K', data_dir='/content/work_directory/data', model_dir='/content/work_directory/models/DeepXML/Astec/EURLex-4K/v_0_108/reranker', result_dir='/content/work_directory/results/DeepXML/Astec/EURLex-4K/v_0_108/reranker', model_fname='model', pred_fname='trn_predictions', trn_feat_fname='trn_X_Xf.txt', val_feat_fname='tst_X_Xf.txt', tst_feat_fname='tst_X_Xf.txt', trn_label_fname='trn_X_Y.txt', val_label_fname='tst_X_Y.txt', feature_type='sparse', tst_label_fname='tst_X_Y.txt', arch='/content/work_directory/programs/deepxml/deepxml/run_scripts/Astec.json', learning_rate=0.005, surrogate_mapping=None, dlr_step=10, last_epoch=0, shortlist_method='static', model_method='reranker', ns_method='ensemble', ann_method='hnsw', seed=108, top_k=100, num_workers=6, ann_threads=18, num_clf_partitions=1, label_indices=None, feature_indices=None, efC=300, num_nbrs=100, efS=400, M=100, retrain_hnsw_after=1, num_labels=3993, vocabulary_dims=40000, padding_idx=0, out_fname='out', dlr_factor=0.5, momentum=0.9, weight_decay=0.0, dropout=0.5, optim='Adam', embedding_dims=300, embeddings='fasttextB_embeddings_300d.npy', validate_after=5, num_epochs=15, batch_size=255, num_centroids=1, beta=0.6, res_init='eye', label_padding_index=3993, mode='train', init='token_embeddings', keep_invalid=True, freeze_intermediate=False, use_shortlist=True, save_intermediate=False, use_pretrained_shortlist=True, validate=True, bias=True, shuffle=True, devices=['cuda:0'], normalize=True, nbn_rel=False, update_shortlist=False, huge_dataset=False, use_intermediate_for_shorty=True, get_only='clf', A=0.55, B=1.5, use_reranker=True, surrogate_threshold=1024, surrogate_method=1, save_predictions=True)\n",
            "\n",
            "Model configuration:  Transform(\n",
            "  (transform): Astec(\n",
            "    (embeddings): Embedding(40001, 300, cuda:0, reduction=sum, padding_idx=0, sparse=True)\n",
            "    (relu): ReLU()\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            ")\n",
            "(Transform fine): Transform(\n",
            "  (transform): Residual(\n",
            "    (hidden_layer): Sequential(\n",
            "      (0): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "(Classifier): SparseLinear(300, 3994, cuda:0, bias=True, padding_idx=3993, sparse=True)\n",
            "\n",
            "Loading training data.\n",
            "Loading validation data.\n",
            "Updating shortlist at epoch: 0\n",
            "ANN train time: 0.00 sec\n",
            "loss: 11.70969: 100% 61/61 [00:06<00:00,  9.00it/s]\n",
            "Epoch: 0, loss: 12.066680, time: 6.78 sec\n",
            "100% 15/15 [00:01<00:00,  8.63it/s]\n",
            "Model saved after epoch: 0\n",
            "P@k (knn): 80.76,73.17,67.04,60.88,55.23 (clf): 58.89,52.89,48.43,44.71,41.25 (ens): 81.10,73.27,67.03,60.76,54.91, loss: 9.139948, time: 1.76 sec\n",
            "loss: 9.50194: 100% 61/61 [00:10<00:00,  5.93it/s]\n",
            "Epoch: 1, loss: 10.185871, time: 10.30 sec\n",
            "loss: 8.86968: 100% 61/61 [00:06<00:00,  9.11it/s]\n",
            "Epoch: 2, loss: 9.196479, time: 6.70 sec\n",
            "loss: 8.46621: 100% 61/61 [00:09<00:00,  6.46it/s]\n",
            "Epoch: 3, loss: 8.417660, time: 9.44 sec\n",
            "loss: 7.84502: 100% 61/61 [00:06<00:00,  8.95it/s]\n",
            "Epoch: 4, loss: 7.723973, time: 6.82 sec\n",
            "loss: 7.40214: 100% 61/61 [00:08<00:00,  7.41it/s]\n",
            "Epoch: 5, loss: 7.145190, time: 8.23 sec\n",
            "100% 15/15 [00:01<00:00,  8.18it/s]\n",
            "Model saved after epoch: 5\n",
            "P@k (knn): 80.76,73.17,67.04,60.88,55.23 (clf): 78.39,70.03,63.74,58.16,52.58 (ens): 82.41,75.26,68.79,62.45,56.49, loss: 7.453973, time: 1.85 sec\n",
            "loss: 6.63786: 100% 61/61 [00:06<00:00,  9.29it/s]\n",
            "Epoch: 6, loss: 6.626582, time: 6.57 sec\n",
            "loss: 5.85726: 100% 61/61 [00:09<00:00,  6.28it/s]\n",
            "Epoch: 7, loss: 6.153297, time: 9.71 sec\n",
            "loss: 5.55592: 100% 61/61 [00:06<00:00,  9.18it/s]\n",
            "Epoch: 8, loss: 5.733979, time: 6.65 sec\n",
            "loss: 5.21424: 100% 61/61 [00:08<00:00,  7.49it/s]\n",
            "Epoch: 9, loss: 5.382181, time: 8.15 sec\n",
            "Adjusted learning rate to: 0.0025\n",
            "loss: 4.68955: 100% 61/61 [00:06<00:00,  9.12it/s]\n",
            "Epoch: 10, loss: 4.941820, time: 6.69 sec\n",
            "100% 15/15 [00:01<00:00,  8.72it/s]\n",
            "Model saved after epoch: 10\n",
            "P@k (knn): 80.76,73.17,67.04,60.88,55.23 (clf): 79.29,72.28,65.90,60.02,54.34 (ens): 83.12,75.73,69.26,62.92,57.04, loss: 7.026683, time: 1.74 sec\n",
            "loss: 4.98275: 100% 61/61 [00:09<00:00,  6.29it/s]\n",
            "Epoch: 11, loss: 4.734235, time: 9.70 sec\n",
            "loss: 4.49582: 100% 61/61 [00:06<00:00,  9.36it/s]\n",
            "Epoch: 12, loss: 4.539924, time: 6.52 sec\n",
            "loss: 4.35820: 100% 61/61 [00:07<00:00,  7.67it/s]\n",
            "Epoch: 13, loss: 4.416151, time: 7.96 sec\n",
            "loss: 4.49731: 100% 61/61 [00:06<00:00,  9.07it/s]\n",
            "Epoch: 14, loss: 4.269975, time: 6.73 sec\n",
            "Purging network checkpoint: checkpoint_net_1.pkl\n",
            "Training time: 116.94 sec, Validation time: 5.34 sec, Shortlist time: 0.00 sec, Model size: 50.71 MB\n",
            "Saving model at: /content/work_directory/models/DeepXML/Astec/EURLex-4K/v_0_108/reranker/model_network.pkl\n",
            "\n",
            "Setting the seed value: 108\n",
            "Model parameters:  Namespace(dataset='EURLex-4K', data_dir='/content/work_directory/data', model_dir='/content/work_directory/models/DeepXML/Astec/EURLex-4K/v_0_108/reranker', result_dir='/content/work_directory/results/DeepXML/Astec/EURLex-4K/v_0_108/reranker', model_fname='model', pred_fname='tst_predictions_reranker', trn_feat_fname='trn_X_Xf.txt', val_feat_fname='tst_X_Xf.txt', tst_feat_fname='tst_X_Xf.txt', trn_label_fname='trn_X_Y.txt', val_label_fname='tst_X_Y.txt', feature_type='sparse', tst_label_fname='tst_X_Y.txt', arch='/content/work_directory/programs/deepxml/deepxml/run_scripts/Astec.json', learning_rate=0.005, surrogate_mapping=None, dlr_step=10, last_epoch=0, shortlist_method='static', model_method='reranker', ns_method='ensemble', ann_method='hnsw', seed=108, top_k=100, num_workers=6, ann_threads=18, num_clf_partitions=1, label_indices=None, feature_indices=None, efC=300, num_nbrs=100, efS=400, M=100, retrain_hnsw_after=1, num_labels=3993, vocabulary_dims=40000, padding_idx=0, out_fname='out', dlr_factor=0.5, momentum=0.9, weight_decay=0.0, dropout=0.5, optim='Adam', embedding_dims=300, embeddings='fasttextB_embeddings_300d.npy', validate_after=5, num_epochs=15, batch_size=255, num_centroids=1, beta=0.6, res_init='eye', label_padding_index=3993, mode='predict', init='token_embeddings', keep_invalid=True, freeze_intermediate=False, use_shortlist=True, save_intermediate=False, use_pretrained_shortlist=True, validate=True, bias=True, shuffle=True, devices=['cuda:0'], normalize=True, nbn_rel=False, update_shortlist=False, huge_dataset=False, use_intermediate_for_shorty=True, get_only='ens', A=0.55, B=1.5, use_reranker=True, surrogate_threshold=1024, surrogate_method=1, save_predictions=True)\n",
            "\n",
            "Model configuration:  Transform(\n",
            "  (transform): Astec(\n",
            "    (embeddings): Embedding(40001, 300, cuda:0, reduction=sum, padding_idx=0, sparse=True)\n",
            "    (relu): ReLU()\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            ")\n",
            "(Transform fine): Transform(\n",
            "  (transform): Residual(\n",
            "    (hidden_layer): Sequential(\n",
            "      (0): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "(Classifier): SparseLinear(300, 3994, cuda:0, bias=True, padding_idx=3993, sparse=True)\n",
            "\n",
            "Shapes are fine, Not padding again.\n",
            "Loading test data.\n",
            "Fetching shortlist.\n",
            "100% 15/15 [00:01<00:00,  8.44it/s]\n",
            "Prediction time (total): 1.79 sec., Prediction time (per sample): 0.47 msec., P@k(%): (knn): 80.76,73.17,67.04,60.88,55.23 (clf): 79.63,72.42,66.19,60.25,54.69 (ens): 82.88,75.49,69.46,63.10,57.12\n",
            "\n",
            "------------------------------\n",
            "classifier\n",
            "82.88,75.49,69.46,63.10,57.12\n",
            "82.88,77.18,72.88,68.98,66.43\n",
            "39.51,43.52,46.63,48.22,49.41\n",
            "39.51,42.48,44.69,45.89,46.77\n",
            "shortlist\n",
            "74.09,64.35,56.45,50.17,45.37\n",
            "74.09,66.57,60.75,56.60,54.39\n",
            "40.47,42.14,42.32,42.25,42.76\n",
            "40.47,41.71,41.90,41.95,42.33\n",
            "beta: 0.10\n",
            "81.86,74.84,68.19,61.86,56.06\n",
            "81.86,76.45,71.72,67.81,65.34\n",
            "41.20,45.23,47.46,48.65,49.77\n",
            "41.20,44.19,45.82,46.75,47.57\n",
            "beta: 0.20\n",
            "82.46,75.48,69.06,62.75,57.05\n",
            "82.46,77.08,72.52,68.66,66.30\n",
            "40.82,44.81,47.41,48.70,50.07\n",
            "40.82,43.78,45.65,46.66,47.64\n",
            "beta: 0.30\n",
            "82.73,75.53,69.32,63.15,57.29\n",
            "82.73,77.18,72.76,69.00,66.55\n",
            "40.52,44.54,47.24,48.82,50.08\n",
            "40.52,43.50,45.44,46.63,47.55\n",
            "beta: 0.40\n",
            "82.91,75.52,69.40,63.23,57.39\n",
            "82.91,77.21,72.85,69.08,66.64\n",
            "40.41,44.26,47.07,48.70,49.98\n",
            "40.41,43.26,45.27,46.48,47.42\n",
            "beta: 0.50\n",
            "82.78,75.52,69.48,63.29,57.42\n",
            "82.78,77.18,72.89,69.10,66.65\n",
            "40.02,44.02,46.99,48.63,49.96\n",
            "40.02,42.98,45.10,46.32,47.29\n",
            "beta: 0.60\n",
            "82.65,75.56,69.50,63.31,57.49\n",
            "82.65,77.18,72.88,69.10,66.68\n",
            "39.84,43.90,46.91,48.53,49.94\n",
            "39.84,42.85,44.99,46.21,47.21\n",
            "beta: 0.75\n",
            "82.75,75.53,69.56,63.34,57.49\n",
            "82.75,77.19,72.94,69.14,66.70\n",
            "39.75,43.76,46.89,48.49,49.88\n",
            "39.75,42.72,44.94,46.14,47.15\n",
            "beta: 0.90\n",
            "82.88,75.49,69.59,63.36,57.56\n",
            "82.88,77.18,72.98,69.17,66.76\n",
            "39.60,43.62,46.81,48.45,49.88\n",
            "39.60,42.58,44.84,46.07,47.09\n",
            "------------------------------\n",
            "\n",
            "\n",
            "------------------------------\n",
            "Training time (sec): 382.84\n",
            "Model size (MB): 132.59\n",
            "Avg. Prediction time (msec): 1.92\n",
            "------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1PVT3CEspIpxhWp8EMcluNvaJfJ8bTTZT",
      "authorship_tag": "ABX9TyNWEXPZwzatZGweQRixIdhW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}